{"id": "golden_001", "category": "causal_lm", "difficulty": "easy", "request": {"task_type": "instruction_following", "model_id": "01-ai/Yi-6B", "model_params": 6000000000, "adapter_type": "qlora", "dataset_name": "dolly", "dataset_size": 15015, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 2048, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0003, "per_device_train_batch_size": 1, "gradient_accumulation_steps": 16, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.9999999999999997e-05, 0.0029999999999999996], "batch_size": [1, 16], "lora_r": [4, 128]}}
{"id": "golden_002", "category": "causal_lm", "difficulty": "easy", "request": {"task_type": "instruction_following", "model_id": "meta-llama/Llama-2-7b-hf", "model_params": 7000000000, "adapter_type": "lora", "dataset_name": "dolly", "dataset_size": 15015, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 2048, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0001, "per_device_train_batch_size": 2, "gradient_accumulation_steps": 8, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1e-05, 0.001], "batch_size": [1, 32], "lora_r": [4, 128]}}
{"id": "golden_003", "category": "causal_lm", "difficulty": "easy", "request": {"task_type": "instruction_following", "model_id": "bert-large-uncased", "model_params": 340000000, "adapter_type": "none", "dataset_name": "dolly", "dataset_size": 15015, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 5e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [5e-06, 0.0005], "batch_size": [1, 64], "lora_r": null}}
{"id": "golden_004", "category": "causal_lm", "difficulty": "easy", "request": {"task_type": "instruction_following", "model_id": "facebook/bart-large", "model_params": 406000000, "adapter_type": "none", "dataset_name": "dolly", "dataset_size": 15015, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 2e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.0000000000000003e-06, 0.0002], "batch_size": [1, 64], "lora_r": null}}
{"id": "golden_005", "category": "causal_lm", "difficulty": "easy", "request": {"task_type": "instruction_following", "model_id": "xlm-roberta-large", "model_params": 550000000, "adapter_type": "none", "dataset_name": "dolly", "dataset_size": 15015, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 1e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1.0000000000000002e-06, 0.0001], "batch_size": [1, 64], "lora_r": null}}
{"id": "golden_006", "category": "causal_lm", "difficulty": "easy", "request": {"task_type": "chat", "model_id": "facebook/bart-large", "model_params": 406000000, "adapter_type": "lora", "dataset_name": "openassistant", "dataset_size": 9846, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 3e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": 16, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [3e-06, 0.00030000000000000003], "batch_size": [1, 64], "lora_r": [4, 128]}}
{"id": "golden_007", "category": "causal_lm", "difficulty": "medium", "request": {"task_type": "chat", "model_id": "meta-llama/Llama-2-13b-hf", "model_params": 13000000000, "adapter_type": "lora", "dataset_name": "openassistant", "dataset_size": 9846, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 1024, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0002, "per_device_train_batch_size": 2, "gradient_accumulation_steps": 8, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2e-05, 0.002], "batch_size": [1, 32], "lora_r": [4, 128]}}
{"id": "golden_008", "category": "causal_lm", "difficulty": "medium", "request": {"task_type": "instruction_following", "model_id": "mistralai/Mistral-7B-v0.1", "model_params": 7000000000, "adapter_type": "lora", "dataset_name": "alpaca", "dataset_size": 52000, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 2048, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0001, "per_device_train_batch_size": 2, "gradient_accumulation_steps": 8, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1e-05, 0.001], "batch_size": [1, 32], "lora_r": [4, 128]}}
{"id": "golden_009", "category": "causal_lm", "difficulty": "medium", "request": {"task_type": "chat", "model_id": "meta-llama/Llama-2-7b-hf", "model_params": 7000000000, "adapter_type": "qlora", "dataset_name": "openassistant", "dataset_size": 9846, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 1024, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0002, "per_device_train_batch_size": 1, "gradient_accumulation_steps": 16, "lora_r": 64, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2e-05, 0.002], "batch_size": [1, 16], "lora_r": [4, 128]}}
{"id": "golden_010", "category": "causal_lm", "difficulty": "medium", "request": {"task_type": "instruction_following", "model_id": "bert-large-uncased", "model_params": 340000000, "adapter_type": "none", "dataset_name": "dolly", "dataset_size": 15015, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 3e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [3e-06, 0.00030000000000000003], "batch_size": [1, 64], "lora_r": null}}
{"id": "golden_011", "category": "causal_lm", "difficulty": "medium", "request": {"task_type": "chat", "model_id": "Qwen/Qwen-7B", "model_params": 7000000000, "adapter_type": "lora", "dataset_name": "openassistant", "dataset_size": 9846, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 2048, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0002, "per_device_train_batch_size": 2, "gradient_accumulation_steps": 8, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2e-05, 0.002], "batch_size": [1, 32], "lora_r": [4, 128]}}
{"id": "golden_012", "category": "causal_lm", "difficulty": "medium", "request": {"task_type": "chat", "model_id": "meta-llama/Llama-2-13b-hf", "model_params": 13000000000, "adapter_type": "qlora", "dataset_name": "openassistant", "dataset_size": 9846, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 1024, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0003, "per_device_train_batch_size": 1, "gradient_accumulation_steps": 16, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.9999999999999997e-05, 0.0029999999999999996], "batch_size": [1, 16], "lora_r": [4, 128]}}
{"id": "golden_013", "category": "causal_lm", "difficulty": "medium", "request": {"task_type": "instruction_following", "model_id": "google/gemma-2b", "model_params": 2000000000, "adapter_type": "lora", "dataset_name": "dolly", "dataset_size": 15015, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 2048, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0001, "per_device_train_batch_size": 2, "gradient_accumulation_steps": 8, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1e-05, 0.001], "batch_size": [1, 32], "lora_r": [4, 128]}}
{"id": "golden_014", "category": "causal_lm", "difficulty": "hard", "request": {"task_type": "instruction_following", "model_id": "tiiuae/falcon-7b", "model_params": 7000000000, "adapter_type": "qlora", "dataset_name": "alpaca", "dataset_size": 52000, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 2048, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0003, "per_device_train_batch_size": 1, "gradient_accumulation_steps": 16, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.9999999999999997e-05, 0.0029999999999999996], "batch_size": [1, 16], "lora_r": [4, 128]}}
{"id": "golden_015", "category": "causal_lm", "difficulty": "hard", "request": {"task_type": "instruction_following", "model_id": "Qwen/Qwen-7B", "model_params": 7000000000, "adapter_type": "qlora", "dataset_name": "alpaca", "dataset_size": 52000, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 2048, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0001, "per_device_train_batch_size": 1, "gradient_accumulation_steps": 16, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1e-05, 0.001], "batch_size": [1, 16], "lora_r": [4, 128]}}
{"id": "golden_016", "category": "causal_lm", "difficulty": "hard", "request": {"task_type": "instruction_following", "model_id": "Qwen/Qwen-7B", "model_params": 7000000000, "adapter_type": "qlora", "dataset_name": "dolly", "dataset_size": 15015, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 2048, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0003, "per_device_train_batch_size": 1, "gradient_accumulation_steps": 16, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.9999999999999997e-05, 0.0029999999999999996], "batch_size": [1, 16], "lora_r": [4, 128]}}
{"id": "golden_017", "category": "causal_lm", "difficulty": "hard", "request": {"task_type": "chat", "model_id": "bert-large-uncased", "model_params": 340000000, "adapter_type": "lora", "dataset_name": "openassistant", "dataset_size": 9846, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 2e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": 16, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.0000000000000003e-06, 0.0002], "batch_size": [1, 64], "lora_r": [4, 128]}}
{"id": "golden_018", "category": "causal_lm", "difficulty": "hard", "request": {"task_type": "instruction_following", "model_id": "t5-large", "model_params": 770000000, "adapter_type": "none", "dataset_name": "alpaca", "dataset_size": 52000, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 3e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [3e-06, 0.00030000000000000003], "batch_size": [1, 64], "lora_r": null}}
{"id": "golden_019", "category": "causal_lm", "difficulty": "hard", "request": {"task_type": "instruction_following", "model_id": "facebook/bart-large", "model_params": 406000000, "adapter_type": "none", "dataset_name": "dolly", "dataset_size": 15015, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 3e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [3e-06, 0.00030000000000000003], "batch_size": [1, 64], "lora_r": null}}
{"id": "golden_020", "category": "causal_lm", "difficulty": "hard", "request": {"task_type": "instruction_following", "model_id": "t5-large", "model_params": 770000000, "adapter_type": "none", "dataset_name": "dolly", "dataset_size": 15015, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 1e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1.0000000000000002e-06, 0.0001], "batch_size": [1, 64], "lora_r": null}}
{"id": "golden_021", "category": "classification", "difficulty": "easy", "request": {"task_type": "text_classification", "model_id": "t5-small", "model_params": 60000000, "adapter_type": "lora", "dataset_name": "yelp_polarity", "dataset_size": 560000, "gpu_type": "V100", "gpu_vram_gb": 16.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 1e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 4, "lora_r": 4, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1.0000000000000002e-06, 0.0001], "batch_size": [1, 64], "lora_r": [4, 128]}}
{"id": "golden_022", "category": "classification", "difficulty": "easy", "request": {"task_type": "sentiment_analysis", "model_id": "t5-base", "model_params": 220000000, "adapter_type": "lora", "dataset_name": "sst2", "dataset_size": 67349, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0002, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2e-05, 0.002], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_023", "category": "classification", "difficulty": "easy", "request": {"task_type": "text_classification", "model_id": "gpt2", "model_params": 124000000, "adapter_type": "lora", "dataset_name": "imdb", "dataset_size": 25000, "gpu_type": "V100", "gpu_vram_gb": 16.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 1e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 4, "lora_r": 4, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1.0000000000000002e-06, 0.0001], "batch_size": [1, 64], "lora_r": [4, 128]}}
{"id": "golden_024", "category": "classification", "difficulty": "easy", "request": {"task_type": "sentiment_analysis", "model_id": "bert-base-multilingual-cased", "model_params": 110000000, "adapter_type": "lora", "dataset_name": "multilingual_sentiment_analysis_en-es", "dataset_size": 78609, "gpu_type": "V100", "gpu_vram_gb": 32.0, "platform": "colab", "plan": "pro", "sequence_length": 256, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 2e-05, "per_device_train_batch_size": 16, "gradient_accumulation_steps": 1, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.0000000000000003e-06, 0.0002], "batch_size": [1, 256], "lora_r": [4, 128]}}
{"id": "golden_025", "category": "classification", "difficulty": "easy", "request": {"task_type": "text_classification", "model_id": "t5-small", "model_params": 60000000, "adapter_type": "lora", "dataset_name": "ag_news", "dataset_size": 120000, "gpu_type": "V100", "gpu_vram_gb": 16.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 1e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 4, "lora_r": 4, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1.0000000000000002e-06, 0.0001], "batch_size": [1, 64], "lora_r": [4, 128]}}
{"id": "golden_026", "category": "classification", "difficulty": "easy", "request": {"task_type": "sentiment_analysis", "model_id": "xlm-roberta-base", "model_params": 270000000, "adapter_type": "lora", "dataset_name": "amazon_reviews_multi", "dataset_size": 210000, "gpu_type": "V100", "gpu_vram_gb": 32.0, "platform": "colab", "plan": "pro", "sequence_length": 256, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 2e-05, "per_device_train_batch_size": 16, "gradient_accumulation_steps": 1, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.0000000000000003e-06, 0.0002], "batch_size": [1, 256], "lora_r": [4, 128]}}
{"id": "golden_027", "category": "classification", "difficulty": "medium", "request": {"task_type": "sentiment_analysis", "model_id": "t5-base", "model_params": 220000000, "adapter_type": "lora", "dataset_name": "twitter_financial", "dataset_size": 11932, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 5e-05, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [5e-06, 0.0005], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_028", "category": "classification", "difficulty": "medium", "request": {"task_type": "text_classification", "model_id": "google/flan-t5-base", "model_params": 250000000, "adapter_type": "lora", "dataset_name": "ag_news", "dataset_size": 120000, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 3e-05, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [3e-06, 0.00030000000000000003], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_029", "category": "classification", "difficulty": "medium", "request": {"task_type": "text_classification", "model_id": "microsoft/phi-2", "model_params": 2700000000, "adapter_type": "lora", "dataset_name": "yelp_polarity", "dataset_size": 560000, "gpu_type": "V100", "gpu_vram_gb": 16.0, "platform": "colab", "plan": "pro", "sequence_length": 1024, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 3e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 4, "lora_r": 4, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [3e-06, 0.00030000000000000003], "batch_size": [1, 64], "lora_r": [4, 128]}}
{"id": "golden_030", "category": "classification", "difficulty": "medium", "request": {"task_type": "text_classification", "model_id": "t5-base", "model_params": 220000000, "adapter_type": "lora", "dataset_name": "imdb", "dataset_size": 25000, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0002, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2e-05, 0.002], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_031", "category": "classification", "difficulty": "medium", "request": {"task_type": "sentiment_analysis", "model_id": "roberta-base", "model_params": 125000000, "adapter_type": "lora", "dataset_name": "twitter_financial", "dataset_size": 11932, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0002, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2e-05, 0.002], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_032", "category": "classification", "difficulty": "medium", "request": {"task_type": "text_classification", "model_id": "facebook/bart-base", "model_params": 140000000, "adapter_type": "lora", "dataset_name": "yelp_polarity", "dataset_size": 560000, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0002, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2e-05, 0.002], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_033", "category": "classification", "difficulty": "medium", "request": {"task_type": "sentiment_analysis", "model_id": "t5-small", "model_params": 60000000, "adapter_type": "lora", "dataset_name": "sst2", "dataset_size": 67349, "gpu_type": "V100", "gpu_vram_gb": 16.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 1e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 4, "lora_r": 4, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1.0000000000000002e-06, 0.0001], "batch_size": [1, 64], "lora_r": [4, 128]}}
{"id": "golden_034", "category": "classification", "difficulty": "hard", "request": {"task_type": "paraphrase", "model_id": "t5-large", "model_params": 770000000, "adapter_type": "lora", "dataset_name": "paws", "dataset_size": 49401, "gpu_type": "A10G", "gpu_vram_gb": 24.0, "platform": "lightning", "plan": "pro", "sequence_length": 1024, "num_gpus": 1, "gpu_override": "A10G_24GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 5e-05, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [5e-06, 0.0005], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_035", "category": "classification", "difficulty": "hard", "request": {"task_type": "sentiment_analysis", "model_id": "roberta-base", "model_params": 125000000, "adapter_type": "lora", "dataset_name": "twitter_financial", "dataset_size": 11932, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 5e-05, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [5e-06, 0.0005], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_036", "category": "classification", "difficulty": "hard", "request": {"task_type": "question_classification", "model_id": "microsoft/deberta-v3-base", "model_params": 184000000, "adapter_type": "none", "dataset_name": "trec", "dataset_size": 5452, "gpu_type": "V100", "gpu_vram_gb": 16.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 2e-05, "per_device_train_batch_size": 16, "gradient_accumulation_steps": 1, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.0000000000000003e-06, 0.0002], "batch_size": [1, 256], "lora_r": null}}
{"id": "golden_037", "category": "classification", "difficulty": "hard", "request": {"task_type": "text_classification", "model_id": "bert-base-uncased", "model_params": 110000000, "adapter_type": "none", "dataset_name": "ag_news", "dataset_size": 120000, "gpu_type": "V100", "gpu_vram_gb": 16.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 2e-05, "per_device_train_batch_size": 16, "gradient_accumulation_steps": 1, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.0000000000000003e-06, 0.0002], "batch_size": [1, 256], "lora_r": null}}
{"id": "golden_038", "category": "classification", "difficulty": "hard", "request": {"task_type": "text_classification", "model_id": "roberta-base", "model_params": 125000000, "adapter_type": "lora", "dataset_name": "imdb", "dataset_size": 25000, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0002, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2e-05, 0.002], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_039", "category": "classification", "difficulty": "hard", "request": {"task_type": "sentiment_analysis", "model_id": "roberta-base", "model_params": 125000000, "adapter_type": "none", "dataset_name": "sst2", "dataset_size": 67349, "gpu_type": "V100", "gpu_vram_gb": 16.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 2e-05, "per_device_train_batch_size": 16, "gradient_accumulation_steps": 1, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.0000000000000003e-06, 0.0002], "batch_size": [1, 256], "lora_r": null}}
{"id": "golden_040", "category": "classification", "difficulty": "hard", "request": {"task_type": "text_classification", "model_id": "t5-small", "model_params": 60000000, "adapter_type": "lora", "dataset_name": "imdb", "dataset_size": 25000, "gpu_type": "V100", "gpu_vram_gb": 16.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 3e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 4, "lora_r": 4, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [3e-06, 0.00030000000000000003], "batch_size": [1, 64], "lora_r": [4, 128]}}
{"id": "golden_041", "category": "qa", "difficulty": "easy", "request": {"task_type": "question_answering", "model_id": "distilbert-base-uncased", "model_params": 66000000, "adapter_type": "lora", "dataset_name": "squad_v2", "dataset_size": 130319, "gpu_type": "V100", "gpu_vram_gb": 16.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0001, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 4, "lora_r": 4, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1e-05, 0.001], "batch_size": [1, 64], "lora_r": [4, 128]}}
{"id": "golden_042", "category": "qa", "difficulty": "easy", "request": {"task_type": "question_answering", "model_id": "xlm-roberta-large", "model_params": 550000000, "adapter_type": "lora", "dataset_name": "newsqa", "dataset_size": 92549, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 3e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": 16, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [3e-06, 0.00030000000000000003], "batch_size": [1, 64], "lora_r": [4, 128]}}
{"id": "golden_043", "category": "qa", "difficulty": "easy", "request": {"task_type": "question_answering", "model_id": "electra-base-discriminator", "model_params": 110000000, "adapter_type": "none", "dataset_name": "hotpot_qa", "dataset_size": 90447, "gpu_type": "V100", "gpu_vram_gb": 32.0, "platform": "colab", "plan": "pro", "sequence_length": 384, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 3e-05, "per_device_train_batch_size": 12, "gradient_accumulation_steps": 2, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [3e-06, 0.00030000000000000003], "batch_size": [1, 192], "lora_r": null}}
{"id": "golden_044", "category": "qa", "difficulty": "easy", "request": {"task_type": "question_answering", "model_id": "google/flan-t5-base", "model_params": 250000000, "adapter_type": "lora", "dataset_name": "newsqa", "dataset_size": 92549, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0001, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1e-05, 0.001], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_045", "category": "qa", "difficulty": "easy", "request": {"task_type": "question_answering", "model_id": "facebook/bart-base", "model_params": 140000000, "adapter_type": "lora", "dataset_name": "squad_v2", "dataset_size": 130319, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 5e-05, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [5e-06, 0.0005], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_046", "category": "qa", "difficulty": "medium", "request": {"task_type": "question_answering", "model_id": "facebook/bart-large", "model_params": 406000000, "adapter_type": "lora", "dataset_name": "newsqa", "dataset_size": 92549, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 1e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": 16, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1.0000000000000002e-06, 0.0001], "batch_size": [1, 64], "lora_r": [4, 128]}}
{"id": "golden_047", "category": "qa", "difficulty": "medium", "request": {"task_type": "question_answering", "model_id": "facebook/bart-base", "model_params": 140000000, "adapter_type": "lora", "dataset_name": "squad", "dataset_size": 87599, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0001, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1e-05, 0.001], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_048", "category": "qa", "difficulty": "medium", "request": {"task_type": "question_answering", "model_id": "t5-small", "model_params": 60000000, "adapter_type": "lora", "dataset_name": "squad_v2", "dataset_size": 130319, "gpu_type": "V100", "gpu_vram_gb": 16.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0003, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 4, "lora_r": 4, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.9999999999999997e-05, 0.0029999999999999996], "batch_size": [1, 64], "lora_r": [4, 128]}}
{"id": "golden_049", "category": "qa", "difficulty": "medium", "request": {"task_type": "question_answering", "model_id": "bert-base-uncased", "model_params": 110000000, "adapter_type": "lora", "dataset_name": "squad_v2", "dataset_size": 130319, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0002, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2e-05, 0.002], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_050", "category": "qa", "difficulty": "medium", "request": {"task_type": "question_answering", "model_id": "bert-large-uncased", "model_params": 340000000, "adapter_type": "none", "dataset_name": "squad", "dataset_size": 87599, "gpu_type": "V100", "gpu_vram_gb": 32.0, "platform": "colab", "plan": "pro", "sequence_length": 384, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 3e-05, "per_device_train_batch_size": 12, "gradient_accumulation_steps": 2, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [3e-06, 0.00030000000000000003], "batch_size": [1, 192], "lora_r": null}}
{"id": "golden_051", "category": "qa", "difficulty": "hard", "request": {"task_type": "question_answering", "model_id": "facebook/bart-large", "model_params": 406000000, "adapter_type": "lora", "dataset_name": "newsqa", "dataset_size": 92549, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 2e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": 16, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.0000000000000003e-06, 0.0002], "batch_size": [1, 64], "lora_r": [4, 128]}}
{"id": "golden_052", "category": "qa", "difficulty": "hard", "request": {"task_type": "question_answering", "model_id": "bert-large-uncased", "model_params": 340000000, "adapter_type": "none", "dataset_name": "newsqa", "dataset_size": 92549, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 5e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [5e-06, 0.0005], "batch_size": [1, 64], "lora_r": null}}
{"id": "golden_053", "category": "qa", "difficulty": "hard", "request": {"task_type": "question_answering", "model_id": "roberta-base", "model_params": 125000000, "adapter_type": "lora", "dataset_name": "newsqa", "dataset_size": 92549, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0001, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1e-05, 0.001], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_054", "category": "qa", "difficulty": "hard", "request": {"task_type": "question_answering", "model_id": "roberta-large", "model_params": 355000000, "adapter_type": "none", "dataset_name": "newsqa", "dataset_size": 92549, "gpu_type": "V100", "gpu_vram_gb": 32.0, "platform": "colab", "plan": "pro", "sequence_length": 384, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 3e-05, "per_device_train_batch_size": 12, "gradient_accumulation_steps": 2, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [3e-06, 0.00030000000000000003], "batch_size": [1, 192], "lora_r": null}}
{"id": "golden_055", "category": "qa", "difficulty": "hard", "request": {"task_type": "question_answering", "model_id": "google/flan-t5-base", "model_params": 250000000, "adapter_type": "lora", "dataset_name": "squad_v2", "dataset_size": 130319, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 5e-05, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [5e-06, 0.0005], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_056", "category": "qa", "difficulty": "hard", "request": {"task_type": "financial_qa", "model_id": "yiyanghkust/finbert-tone", "model_params": 110000000, "adapter_type": "none", "dataset_name": "fiqa", "dataset_size": 6648, "gpu_type": "V100", "gpu_vram_gb": 16.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 2e-05, "per_device_train_batch_size": 16, "gradient_accumulation_steps": 1, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.0000000000000003e-06, 0.0002], "batch_size": [1, 256], "lora_r": null}}
{"id": "golden_057", "category": "summarization", "difficulty": "easy", "request": {"task_type": "summarization", "model_id": "bert-large-uncased", "model_params": 340000000, "adapter_type": "lora", "dataset_name": "cnn_dailymail", "dataset_size": 287113, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 5e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": 16, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [5e-06, 0.0005], "batch_size": [1, 64], "lora_r": [4, 128]}}
{"id": "golden_058", "category": "summarization", "difficulty": "easy", "request": {"task_type": "summarization", "model_id": "google/flan-t5-base", "model_params": 250000000, "adapter_type": "lora", "dataset_name": "xsum", "dataset_size": 204045, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0001, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1e-05, 0.001], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_059", "category": "summarization", "difficulty": "easy", "request": {"task_type": "summarization", "model_id": "bert-base-uncased", "model_params": 110000000, "adapter_type": "lora", "dataset_name": "cnn_dailymail", "dataset_size": 287113, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 5e-05, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [5e-06, 0.0005], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_060", "category": "summarization", "difficulty": "easy", "request": {"task_type": "summarization", "model_id": "t5-base", "model_params": 220000000, "adapter_type": "lora", "dataset_name": "xsum", "dataset_size": 204045, "gpu_type": "A10G", "gpu_vram_gb": 24.0, "platform": "lightning", "plan": "pro", "sequence_length": 1024, "num_gpus": 1, "gpu_override": "A10G_24GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 5e-05, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [5e-06, 0.0005], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_061", "category": "summarization", "difficulty": "medium", "request": {"task_type": "summarization", "model_id": "xlm-roberta-large", "model_params": 550000000, "adapter_type": "none", "dataset_name": "cnn_dailymail", "dataset_size": 287113, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 3e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [3e-06, 0.00030000000000000003], "batch_size": [1, 64], "lora_r": null}}
{"id": "golden_062", "category": "summarization", "difficulty": "medium", "request": {"task_type": "summarization", "model_id": "bert-base-uncased", "model_params": 110000000, "adapter_type": "lora", "dataset_name": "xsum", "dataset_size": 204045, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 3e-05, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [3e-06, 0.00030000000000000003], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_063", "category": "summarization", "difficulty": "medium", "request": {"task_type": "summarization", "model_id": "t5-large", "model_params": 770000000, "adapter_type": "none", "dataset_name": "xsum", "dataset_size": 204045, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 3e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [3e-06, 0.00030000000000000003], "batch_size": [1, 64], "lora_r": null}}
{"id": "golden_064", "category": "summarization", "difficulty": "medium", "request": {"task_type": "summarization", "model_id": "facebook/bart-base", "model_params": 140000000, "adapter_type": "lora", "dataset_name": "samsum", "dataset_size": 14732, "gpu_type": "A10G", "gpu_vram_gb": 24.0, "platform": "lightning", "plan": "pro", "sequence_length": 1024, "num_gpus": 1, "gpu_override": "A10G_24GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 5e-05, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [5e-06, 0.0005], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_065", "category": "summarization", "difficulty": "hard", "request": {"task_type": "summarization", "model_id": "google/flan-t5-base", "model_params": 250000000, "adapter_type": "lora", "dataset_name": "cnn_dailymail", "dataset_size": 287113, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0002, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2e-05, 0.002], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_066", "category": "summarization", "difficulty": "hard", "request": {"task_type": "summarization", "model_id": "roberta-base", "model_params": 125000000, "adapter_type": "lora", "dataset_name": "cnn_dailymail", "dataset_size": 287113, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 5e-05, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [5e-06, 0.0005], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_067", "category": "summarization", "difficulty": "hard", "request": {"task_type": "summarization", "model_id": "t5-large", "model_params": 770000000, "adapter_type": "none", "dataset_name": "cnn_dailymail", "dataset_size": 287113, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 5e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [5e-06, 0.0005], "batch_size": [1, 64], "lora_r": null}}
{"id": "golden_068", "category": "summarization", "difficulty": "hard", "request": {"task_type": "summarization", "model_id": "facebook/bart-base", "model_params": 140000000, "adapter_type": "lora", "dataset_name": "cnn_dailymail", "dataset_size": 287113, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0002, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2e-05, 0.002], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_069", "category": "translation", "difficulty": "easy", "request": {"task_type": "translation", "model_id": "roberta-base", "model_params": 125000000, "adapter_type": "lora", "dataset_name": "wmt14_de_en", "dataset_size": 4500000, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0001, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1e-05, 0.001], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_070", "category": "translation", "difficulty": "easy", "request": {"task_type": "translation", "model_id": "facebook/bart-large", "model_params": 406000000, "adapter_type": "none", "dataset_name": "wmt14_de_en", "dataset_size": 4500000, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 3e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [3e-06, 0.00030000000000000003], "batch_size": [1, 64], "lora_r": null}}
{"id": "golden_071", "category": "translation", "difficulty": "easy", "request": {"task_type": "translation", "model_id": "roberta-base", "model_params": 125000000, "adapter_type": "lora", "dataset_name": "wmt14_de_en", "dataset_size": 4500000, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 3e-05, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [3e-06, 0.00030000000000000003], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_072", "category": "translation", "difficulty": "medium", "request": {"task_type": "translation", "model_id": "google/mt5-base", "model_params": 580000000, "adapter_type": "lora", "dataset_name": "multilingual_translation_en-es", "dataset_size": 136893, "gpu_type": "V100", "gpu_vram_gb": 32.0, "platform": "colab", "plan": "pro", "sequence_length": 256, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 2e-05, "per_device_train_batch_size": 16, "gradient_accumulation_steps": 1, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.0000000000000003e-06, 0.0002], "batch_size": [1, 256], "lora_r": [4, 128]}}
{"id": "golden_073", "category": "translation", "difficulty": "medium", "request": {"task_type": "translation", "model_id": "google/mt5-base", "model_params": 580000000, "adapter_type": "lora", "dataset_name": "multilingual_translation_en-fr", "dataset_size": 138619, "gpu_type": "V100", "gpu_vram_gb": 32.0, "platform": "colab", "plan": "pro", "sequence_length": 256, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 2e-05, "per_device_train_batch_size": 16, "gradient_accumulation_steps": 1, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.0000000000000003e-06, 0.0002], "batch_size": [1, 256], "lora_r": [4, 128]}}
{"id": "golden_074", "category": "translation", "difficulty": "medium", "request": {"task_type": "translation", "model_id": "facebook/bart-base", "model_params": 140000000, "adapter_type": "lora", "dataset_name": "wmt14_de_en", "dataset_size": 4500000, "gpu_type": "A10G", "gpu_vram_gb": 24.0, "platform": "lightning", "plan": "pro", "sequence_length": 1024, "num_gpus": 1, "gpu_override": "A10G_24GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 5e-05, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [5e-06, 0.0005], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_075", "category": "translation", "difficulty": "hard", "request": {"task_type": "translation", "model_id": "facebook/bart-large", "model_params": 406000000, "adapter_type": "none", "dataset_name": "wmt14_de_en", "dataset_size": 4500000, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 2e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.0000000000000003e-06, 0.0002], "batch_size": [1, 64], "lora_r": null}}
{"id": "golden_076", "category": "translation", "difficulty": "hard", "request": {"task_type": "translation", "model_id": "bert-large-uncased", "model_params": 340000000, "adapter_type": "none", "dataset_name": "wmt14_de_en", "dataset_size": 4500000, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 5e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [5e-06, 0.0005], "batch_size": [1, 64], "lora_r": null}}
{"id": "golden_077", "category": "translation", "difficulty": "hard", "request": {"task_type": "translation", "model_id": "google/mt5-small", "model_params": 300000000, "adapter_type": "lora", "dataset_name": "multilingual_translation_en-es", "dataset_size": 83519, "gpu_type": "V100", "gpu_vram_gb": 32.0, "platform": "colab", "plan": "pro", "sequence_length": 256, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 2e-05, "per_device_train_batch_size": 16, "gradient_accumulation_steps": 1, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.0000000000000003e-06, 0.0002], "batch_size": [1, 256], "lora_r": [4, 128]}}
{"id": "golden_078", "category": "translation", "difficulty": "hard", "request": {"task_type": "translation", "model_id": "t5-large", "model_params": 770000000, "adapter_type": "none", "dataset_name": "wmt14_de_en", "dataset_size": 4500000, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 2e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.0000000000000003e-06, 0.0002], "batch_size": [1, 64], "lora_r": null}}
{"id": "golden_079", "category": "code", "difficulty": "easy", "request": {"task_type": "code_generation", "model_id": "mistralai/Mistral-7B-v0.1", "model_params": 7000000000, "adapter_type": "lora", "dataset_name": "mbpp", "dataset_size": 974, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 2048, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0001, "per_device_train_batch_size": 2, "gradient_accumulation_steps": 8, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1e-05, 0.001], "batch_size": [1, 32], "lora_r": [4, 128]}}
{"id": "golden_080", "category": "code", "difficulty": "easy", "request": {"task_type": "code_generation", "model_id": "bert-large-uncased", "model_params": 340000000, "adapter_type": "lora", "dataset_name": "mbpp", "dataset_size": 974, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 2e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": 16, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.0000000000000003e-06, 0.0002], "batch_size": [1, 64], "lora_r": [4, 128]}}
{"id": "golden_081", "category": "code", "difficulty": "easy", "request": {"task_type": "code_generation", "model_id": "google/gemma-2b", "model_params": 2000000000, "adapter_type": "lora", "dataset_name": "mbpp", "dataset_size": 974, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 2048, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0001, "per_device_train_batch_size": 2, "gradient_accumulation_steps": 8, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1e-05, 0.001], "batch_size": [1, 32], "lora_r": [4, 128]}}
{"id": "golden_082", "category": "code", "difficulty": "easy", "request": {"task_type": "code_generation", "model_id": "xlm-roberta-large", "model_params": 550000000, "adapter_type": "none", "dataset_name": "code_search_net", "dataset_size": 2326976, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 3e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [3e-06, 0.00030000000000000003], "batch_size": [1, 64], "lora_r": null}}
{"id": "golden_083", "category": "code", "difficulty": "medium", "request": {"task_type": "code_generation", "model_id": "codegen-2B-mono", "model_params": 2000000000, "adapter_type": "lora", "dataset_name": "humaneval", "dataset_size": 164, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 2048, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 1e-05, "per_device_train_batch_size": 2, "gradient_accumulation_steps": 8, "lora_r": 16, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1.0000000000000002e-06, 0.0001], "batch_size": [1, 32], "lora_r": [4, 128]}}
{"id": "golden_084", "category": "code", "difficulty": "medium", "request": {"task_type": "code_generation", "model_id": "xlm-roberta-large", "model_params": 550000000, "adapter_type": "lora", "dataset_name": "code_search_net", "dataset_size": 2326976, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 2e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": 16, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.0000000000000003e-06, 0.0002], "batch_size": [1, 64], "lora_r": [4, 128]}}
{"id": "golden_085", "category": "code", "difficulty": "medium", "request": {"task_type": "code_generation", "model_id": "xlm-roberta-large", "model_params": 550000000, "adapter_type": "none", "dataset_name": "code_search_net", "dataset_size": 2326976, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 1e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1.0000000000000002e-06, 0.0001], "batch_size": [1, 64], "lora_r": null}}
{"id": "golden_086", "category": "code", "difficulty": "medium", "request": {"task_type": "code_generation", "model_id": "t5-large", "model_params": 770000000, "adapter_type": "none", "dataset_name": "mbpp", "dataset_size": 974, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 2e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.0000000000000003e-06, 0.0002], "batch_size": [1, 64], "lora_r": null}}
{"id": "golden_087", "category": "code", "difficulty": "medium", "request": {"task_type": "code_generation", "model_id": "codegen-350M-mono", "model_params": 350000000, "adapter_type": "none", "dataset_name": "code_search_net", "dataset_size": 2326976, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 2048, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 5e-05, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 8, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [5e-06, 0.0005], "batch_size": [1, 128], "lora_r": null}}
{"id": "golden_088", "category": "code", "difficulty": "hard", "request": {"task_type": "code_generation", "model_id": "meta-llama/Llama-2-7b-hf", "model_params": 7000000000, "adapter_type": "qlora", "dataset_name": "code_search_net", "dataset_size": 2326976, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 2048, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0002, "per_device_train_batch_size": 1, "gradient_accumulation_steps": 16, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2e-05, 0.002], "batch_size": [1, 16], "lora_r": [4, 128]}}
{"id": "golden_089", "category": "code", "difficulty": "hard", "request": {"task_type": "code_generation", "model_id": "google/gemma-2b", "model_params": 2000000000, "adapter_type": "qlora", "dataset_name": "code_search_net", "dataset_size": 2326976, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 2048, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0002, "per_device_train_batch_size": 1, "gradient_accumulation_steps": 16, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2e-05, 0.002], "batch_size": [1, 16], "lora_r": [4, 128]}}
{"id": "golden_090", "category": "code", "difficulty": "hard", "request": {"task_type": "code_generation", "model_id": "mistralai/Mistral-7B-v0.1", "model_params": 7000000000, "adapter_type": "lora", "dataset_name": "code_search_net", "dataset_size": 2326976, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 2048, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0003, "per_device_train_batch_size": 2, "gradient_accumulation_steps": 8, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.9999999999999997e-05, 0.0029999999999999996], "batch_size": [1, 32], "lora_r": [4, 128]}}
{"id": "golden_091", "category": "code", "difficulty": "hard", "request": {"task_type": "code_generation", "model_id": "tiiuae/falcon-7b", "model_params": 7000000000, "adapter_type": "lora", "dataset_name": "code_search_net", "dataset_size": 2326976, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 2048, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0002, "per_device_train_batch_size": 2, "gradient_accumulation_steps": 8, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2e-05, 0.002], "batch_size": [1, 32], "lora_r": [4, 128]}}
{"id": "golden_092", "category": "code", "difficulty": "hard", "request": {"task_type": "code_generation", "model_id": "bert-large-uncased", "model_params": 340000000, "adapter_type": "none", "dataset_name": "mbpp", "dataset_size": 974, "gpu_type": "A100", "gpu_vram_gb": 80.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 2e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 8, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [2.0000000000000003e-06, 0.0002], "batch_size": [1, 64], "lora_r": null}}
{"id": "golden_093", "category": "ner", "difficulty": "easy", "request": {"task_type": "named_entity_recognition", "model_id": "facebook/bart-base", "model_params": 140000000, "adapter_type": "lora", "dataset_name": "wnut_17", "dataset_size": 3394, "gpu_type": "A100", "gpu_vram_gb": 40.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "A100_40GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 5e-05, "per_device_train_batch_size": 8, "gradient_accumulation_steps": 4, "lora_r": 8, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [5e-06, 0.0005], "batch_size": [1, 128], "lora_r": [4, 128]}}
{"id": "golden_094", "category": "ner", "difficulty": "easy", "request": {"task_type": "named_entity_recognition", "model_id": "distilbert-base-uncased", "model_params": 66000000, "adapter_type": "lora", "dataset_name": "wnut_17", "dataset_size": 3394, "gpu_type": "V100", "gpu_vram_gb": 16.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 3e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 4, "lora_r": 4, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [3e-06, 0.00030000000000000003], "batch_size": [1, 64], "lora_r": [4, 128]}}
{"id": "golden_095", "category": "ner", "difficulty": "medium", "request": {"task_type": "named_entity_recognition", "model_id": "xlm-roberta-base", "model_params": 270000000, "adapter_type": "none", "dataset_name": "mit_movie", "dataset_size": 9775, "gpu_type": "V100", "gpu_vram_gb": 16.0, "platform": "colab", "plan": "pro", "sequence_length": 512, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 5e-05, "per_device_train_batch_size": 16, "gradient_accumulation_steps": 1, "lora_r": null, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [5e-06, 0.0005], "batch_size": [1, 256], "lora_r": null}}
{"id": "golden_096", "category": "ner", "difficulty": "medium", "request": {"task_type": "named_entity_recognition", "model_id": "microsoft/phi-2", "model_params": 2700000000, "adapter_type": "lora", "dataset_name": "conll2003", "dataset_size": 14041, "gpu_type": "V100", "gpu_vram_gb": 16.0, "platform": "colab", "plan": "pro", "sequence_length": 1024, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 3e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 4, "lora_r": 4, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [3e-06, 0.00030000000000000003], "batch_size": [1, 64], "lora_r": [4, 128]}}
{"id": "golden_097", "category": "ner", "difficulty": "hard", "request": {"task_type": "named_entity_recognition", "model_id": "microsoft/phi-2", "model_params": 2700000000, "adapter_type": "lora", "dataset_name": "ontonotes", "dataset_size": 59924, "gpu_type": "V100", "gpu_vram_gb": 16.0, "platform": "colab", "plan": "pro", "sequence_length": 1024, "num_gpus": 1, "gpu_override": "V100_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 3e-05, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 4, "lora_r": 4, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [3e-06, 0.00030000000000000003], "batch_size": [1, 64], "lora_r": [4, 128]}}
{"id": "golden_098", "category": "ood_synthetic", "difficulty": "hard", "request": {"task_type": "totally_unknown_task_family", "model_id": "meta-llama/Llama-2-7b-hf", "model_params": 7000000000, "adapter_type": "qlora", "dataset_name": "unknown_dataset", "dataset_size": 10000, "gpu_type": "T4", "gpu_vram_gb": 16.0, "platform": "colab", "plan": "free", "sequence_length": 1024, "num_gpus": 1, "gpu_override": "T4_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0002, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 4, "lora_r": 16, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1e-05, 0.0005], "batch_size": [1, 8], "lora_r": [4, 64]}}
{"id": "golden_099", "category": "ood_synthetic", "difficulty": "hard", "request": {"task_type": "x_bio_ner_future", "model_id": "google/gemma-7b", "model_params": 7000000000, "adapter_type": "qlora", "dataset_name": "synthetic_bio", "dataset_size": 5000, "gpu_type": "T4", "gpu_vram_gb": 16.0, "platform": "colab", "plan": "free", "sequence_length": 1024, "num_gpus": 1, "gpu_override": "T4_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0002, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 4, "lora_r": 16, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1e-05, 0.0005], "batch_size": [1, 8], "lora_r": [4, 64]}}
{"id": "golden_100", "category": "ood_synthetic", "difficulty": "hard", "request": {"task_type": "robotics_dialog_policy", "model_id": "mistralai/Mistral-7B-v0.1", "model_params": 7000000000, "adapter_type": "qlora", "dataset_name": "robotics_policy", "dataset_size": 8000, "gpu_type": "T4", "gpu_vram_gb": 16.0, "platform": "colab", "plan": "free", "sequence_length": 1024, "num_gpus": 1, "gpu_override": "T4_16GB", "strategy": "deterministic"}, "ground_truth": {"learning_rate": 0.0002, "per_device_train_batch_size": 4, "gradient_accumulation_steps": 4, "lora_r": 16, "known_safe_on_gpu": true}, "acceptable_ranges": {"learning_rate": [1e-05, 0.0005], "batch_size": [1, 8], "lora_r": [4, 64]}}
