{"id": "bert_class_001", "task_type": "classification", "task_description": "BERT classification on imdb", "use_case": "Text classification - imdb", "dataset": {"name": "imdb", "size": 25000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 4, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_baselines", "tags": ["classification", "bert", "imdb"], "validated": true}
{"id": "bert_class_002", "task_type": "classification", "task_description": "BERT classification on ag_news", "use_case": "Text classification - ag_news", "dataset": {"name": "ag_news", "size": 120000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 3e-05, "num_epochs": 3, "batch_size": 32, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_baselines", "tags": ["classification", "bert", "ag_news"], "validated": true}
{"id": "bert_class_003", "task_type": "classification", "task_description": "BERT classification on sst2", "use_case": "Text classification - sst2", "dataset": {"name": "sst2", "size": 67000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_baselines", "tags": ["classification", "bert", "sst2"], "validated": true}
{"id": "bert_class_004", "task_type": "classification", "task_description": "BERT classification on sst2", "use_case": "Text classification - sst2", "dataset": {"name": "sst2", "size": 67000, "format": "hf_dataset"}, "model": {"name": "bert-large-uncased", "size_params": "340M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-large-uncased"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_baselines", "tags": ["classification", "bert", "sst2"], "validated": true}
{"id": "bert_class_005", "task_type": "classification", "task_description": "BERT classification on cola", "use_case": "Text classification - cola", "dataset": {"name": "cola", "size": 8551, "format": "hf_dataset"}, "model": {"name": "bert-base-cased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-cased"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_baselines", "tags": ["classification", "bert", "cola"], "validated": true}
{"id": "bert_class_006", "task_type": "classification", "task_description": "BERT classification on mrpc", "use_case": "Text classification - mrpc", "dataset": {"name": "mrpc", "size": 3668, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_baselines", "tags": ["classification", "bert", "mrpc"], "validated": true}
{"id": "bert_class_007", "task_type": "classification", "task_description": "BERT classification on qnli", "use_case": "Text classification - qnli", "dataset": {"name": "qnli", "size": 104743, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 3e-05, "num_epochs": 2, "batch_size": 32, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_baselines", "tags": ["classification", "bert", "qnli"], "validated": true}
{"id": "bert_class_008", "task_type": "classification", "task_description": "BERT classification on qqp", "use_case": "Text classification - qqp", "dataset": {"name": "qqp", "size": 363846, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 3e-05, "num_epochs": 3, "batch_size": 32, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_baselines", "tags": ["classification", "bert", "qqp"], "validated": true}
{"id": "bert_class_009", "task_type": "classification", "task_description": "BERT classification on rte", "use_case": "Text classification - rte", "dataset": {"name": "rte", "size": 2490, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 4, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_baselines", "tags": ["classification", "bert", "rte"], "validated": true}
{"id": "bert_class_010", "task_type": "classification", "task_description": "BERT classification on xnli", "use_case": "Text classification - xnli", "dataset": {"name": "xnli", "size": 392702, "format": "hf_dataset"}, "model": {"name": "bert-base-multilingual-cased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-multilingual-cased"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 32, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_baselines", "tags": ["classification", "bert", "xnli"], "validated": true}
{"id": "llama2_qlora_001", "task_type": "chatbot", "task_description": "Llama-2-7B QLoRA on guanaco-llama2-1k", "use_case": "Instruction-following chatbot", "dataset": {"name": "guanaco-llama2-1k", "size": 1000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 64, "lora_alpha": 16, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj", "k_proj", "o_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama2_qlora", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama2_qlora_002", "task_type": "chatbot", "task_description": "Llama-2-7B QLoRA on openassistant-guanaco", "use_case": "Instruction-following chatbot", "dataset": {"name": "openassistant-guanaco", "size": 10000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 64, "lora_alpha": 16, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj", "k_proj", "o_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama2_qlora", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama2_qlora_003", "task_type": "chatbot", "task_description": "Llama-2-7B QLoRA on alpaca-cleaned", "use_case": "Instruction-following chatbot", "dataset": {"name": "alpaca-cleaned", "size": 52000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 32, "lora_alpha": 64, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj", "k_proj", "o_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama2_qlora", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama2_qlora_004", "task_type": "chatbot", "task_description": "Llama-2-7B QLoRA on dolly-15k", "use_case": "Instruction-following chatbot", "dataset": {"name": "dolly-15k", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 16, "lora_alpha": 32, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj", "k_proj", "o_proj"]}, "training_config": {"learning_rate": 0.0003, "num_epochs": 1, "batch_size": 8, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama2_qlora", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama2_qlora_005", "task_type": "chatbot", "task_description": "Llama-2-7B QLoRA on alpaca", "use_case": "Instruction-following chatbot", "dataset": {"name": "alpaca", "size": 52000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 8, "lora_alpha": 16, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj", "k_proj", "o_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama2_qlora", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama2_qlora_006", "task_type": "chatbot", "task_description": "Llama-2-7B QLoRA on guanaco-llama2-1k", "use_case": "Instruction-following chatbot", "dataset": {"name": "guanaco-llama2-1k", "size": 1000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 64, "lora_alpha": 128, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj", "k_proj", "o_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 2, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama2_qlora", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama2_qlora_007", "task_type": "chatbot", "task_description": "Llama-2-7B QLoRA on openassistant-guanaco", "use_case": "Instruction-following chatbot", "dataset": {"name": "openassistant-guanaco", "size": 10000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 32, "lora_alpha": 64, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj", "k_proj", "o_proj"]}, "training_config": {"learning_rate": 0.0001, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama2_qlora", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama2_qlora_008", "task_type": "chatbot", "task_description": "Llama-2-7B QLoRA on alpaca-cleaned", "use_case": "Instruction-following chatbot", "dataset": {"name": "alpaca-cleaned", "size": 52000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 16, "lora_alpha": 32, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj", "k_proj", "o_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 8, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama2_qlora", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama2_qlora_009", "task_type": "chatbot", "task_description": "Llama-2-7B QLoRA on dolly-15k", "use_case": "Instruction-following chatbot", "dataset": {"name": "dolly-15k", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 64, "lora_alpha": 16, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj", "k_proj", "o_proj"]}, "training_config": {"learning_rate": 0.0003, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama2_qlora", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama2_qlora_010", "task_type": "chatbot", "task_description": "Llama-2-7B QLoRA on alpaca", "use_case": "Instruction-following chatbot", "dataset": {"name": "alpaca", "size": 52000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 32, "lora_alpha": 64, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj", "k_proj", "o_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama2_qlora", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "summarization_001", "task_type": "summarization", "task_description": "t5-small summarization on cnn_dailymail", "use_case": "Text summarization - cnn_dailymail", "dataset": {"name": "cnn_dailymail", "size": 287000, "format": "hf_dataset"}, "model": {"name": "t5-small", "size_params": "60M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-small"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_baselines", "tags": ["summarization", "cnn_dailymail"], "validated": true}
{"id": "summarization_002", "task_type": "summarization", "task_description": "t5-small summarization on xsum", "use_case": "Text summarization - xsum", "dataset": {"name": "xsum", "size": 204000, "format": "hf_dataset"}, "model": {"name": "t5-small", "size_params": "60M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-small"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_baselines", "tags": ["summarization", "xsum"], "validated": true}
{"id": "summarization_003", "task_type": "summarization", "task_description": "t5-small summarization on samsum", "use_case": "Text summarization - samsum", "dataset": {"name": "samsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "t5-small", "size_params": "60M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-small"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_baselines", "tags": ["summarization", "samsum"], "validated": true}
{"id": "summarization_004", "task_type": "summarization", "task_description": "t5-base summarization on cnn_dailymail", "use_case": "Text summarization - cnn_dailymail", "dataset": {"name": "cnn_dailymail", "size": 287000, "format": "hf_dataset"}, "model": {"name": "t5-base", "size_params": "220M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_baselines", "tags": ["summarization", "cnn_dailymail"], "validated": true}
{"id": "summarization_005", "task_type": "summarization", "task_description": "t5-base summarization on xsum", "use_case": "Text summarization - xsum", "dataset": {"name": "xsum", "size": 204000, "format": "hf_dataset"}, "model": {"name": "t5-base", "size_params": "220M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_baselines", "tags": ["summarization", "xsum"], "validated": true}
{"id": "summarization_006", "task_type": "summarization", "task_description": "facebook/bart-base summarization on cnn_dailymail", "use_case": "Text summarization - cnn_dailymail", "dataset": {"name": "cnn_dailymail", "size": 287000, "format": "hf_dataset"}, "model": {"name": "facebook/bart-base", "size_params": "140M", "architecture": "BartForConditionalGeneration", "hf_hub_id": "facebook/bart-base"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_baselines", "tags": ["summarization", "cnn_dailymail"], "validated": true}
{"id": "summarization_007", "task_type": "summarization", "task_description": "facebook/bart-base summarization on xsum", "use_case": "Text summarization - xsum", "dataset": {"name": "xsum", "size": 204000, "format": "hf_dataset"}, "model": {"name": "facebook/bart-base", "size_params": "140M", "architecture": "BartForConditionalGeneration", "hf_hub_id": "facebook/bart-base"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_baselines", "tags": ["summarization", "xsum"], "validated": true}
{"id": "summarization_008", "task_type": "summarization", "task_description": "facebook/bart-large summarization on cnn_dailymail", "use_case": "Text summarization - cnn_dailymail", "dataset": {"name": "cnn_dailymail", "size": 287000, "format": "hf_dataset"}, "model": {"name": "facebook/bart-large", "size_params": "406M", "architecture": "BartForConditionalGeneration", "hf_hub_id": "facebook/bart-large"}, "training_config": {"learning_rate": 3e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_baselines", "tags": ["summarization", "cnn_dailymail"], "validated": true}
{"id": "summarization_009", "task_type": "summarization", "task_description": "facebook/bart-large-cnn summarization on samsum", "use_case": "Text summarization - samsum", "dataset": {"name": "samsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "facebook/bart-large-cnn", "size_params": "406M", "architecture": "BartForConditionalGeneration", "hf_hub_id": "facebook/bart-large-cnn"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 4, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_baselines", "tags": ["summarization", "samsum"], "validated": true}
{"id": "summarization_010", "task_type": "summarization", "task_description": "t5-large summarization on cnn_dailymail", "use_case": "Text summarization - cnn_dailymail", "dataset": {"name": "cnn_dailymail", "size": 287000, "format": "hf_dataset"}, "model": {"name": "t5-large", "size_params": "770M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-large"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "V100", "gpu_memory_gb": 32, "quantization": "none"}, "source": "summarization_baselines", "tags": ["summarization", "cnn_dailymail"], "validated": true}
{"id": "qa_001", "task_type": "question_answering", "task_description": "bert-base-uncased QA on squad", "use_case": "Extractive question answering", "dataset": {"name": "squad", "size": 87000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForQuestionAnswering", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 3e-05, "num_epochs": 2, "batch_size": 12, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "qa_baselines", "tags": ["qa", "squad"], "validated": true}
{"id": "qa_002", "task_type": "question_answering", "task_description": "bert-large-uncased QA on squad", "use_case": "Extractive question answering", "dataset": {"name": "squad", "size": 87000, "format": "hf_dataset"}, "model": {"name": "bert-large-uncased", "size_params": "340M", "architecture": "BertForQuestionAnswering", "hf_hub_id": "bert-large-uncased"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 2, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "qa_baselines", "tags": ["qa", "squad"], "validated": true}
{"id": "qa_003", "task_type": "question_answering", "task_description": "roberta-base QA on squad_v2", "use_case": "Extractive question answering", "dataset": {"name": "squad_v2", "size": 130000, "format": "hf_dataset"}, "model": {"name": "roberta-base", "size_params": "110M", "architecture": "BertForQuestionAnswering", "hf_hub_id": "roberta-base"}, "training_config": {"learning_rate": 3e-05, "num_epochs": 2, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "qa_baselines", "tags": ["qa", "squad_v2"], "validated": true}
{"id": "qa_004", "task_type": "question_answering", "task_description": "distilbert-base-uncased QA on squad", "use_case": "Extractive question answering", "dataset": {"name": "squad", "size": 87000, "format": "hf_dataset"}, "model": {"name": "distilbert-base-uncased", "size_params": "110M", "architecture": "BertForQuestionAnswering", "hf_hub_id": "distilbert-base-uncased"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 2, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "qa_baselines", "tags": ["qa", "squad"], "validated": true}
{"id": "qa_005", "task_type": "question_answering", "task_description": "bert-base-cased QA on squad", "use_case": "Extractive question answering", "dataset": {"name": "squad", "size": 87000, "format": "hf_dataset"}, "model": {"name": "bert-base-cased", "size_params": "110M", "architecture": "BertForQuestionAnswering", "hf_hub_id": "bert-base-cased"}, "training_config": {"learning_rate": 3e-05, "num_epochs": 2, "batch_size": 12, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "qa_baselines", "tags": ["qa", "squad"], "validated": true}
{"id": "whisper_asr_001", "task_type": "speech_recognition", "task_description": "Whisper en ASR on librispeech", "use_case": "Speech recognition - en", "dataset": {"name": "librispeech", "size": 960, "format": "audio", "language": "en"}, "model": {"name": "openai/whisper-tiny", "size_params": "39M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-tiny"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_official", "tags": ["asr", "speech", "whisper", "en"], "validated": true}
{"id": "whisper_asr_002", "task_type": "speech_recognition", "task_description": "Whisper en ASR on librispeech", "use_case": "Speech recognition - en", "dataset": {"name": "librispeech", "size": 960, "format": "audio", "language": "en"}, "model": {"name": "openai/whisper-base", "size_params": "74M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-base"}, "training_config": {"learning_rate": 1e-05, "batch_size": 32, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_official", "tags": ["asr", "speech", "whisper", "en"], "validated": true}
{"id": "whisper_asr_003", "task_type": "speech_recognition", "task_description": "Whisper en ASR on librispeech", "use_case": "Speech recognition - en", "dataset": {"name": "librispeech", "size": 960, "format": "audio", "language": "en"}, "model": {"name": "openai/whisper-small", "size_params": "244M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-small"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_official", "tags": ["asr", "speech", "whisper", "en"], "validated": true}
{"id": "whisper_asr_004", "task_type": "speech_recognition", "task_description": "Whisper en ASR on librispeech", "use_case": "Speech recognition - en", "dataset": {"name": "librispeech", "size": 960, "format": "audio", "language": "en"}, "model": {"name": "openai/whisper-medium", "size_params": "769M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-medium"}, "training_config": {"learning_rate": 5e-06, "batch_size": 8, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "A100", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_official", "tags": ["asr", "speech", "whisper", "en"], "validated": true}
{"id": "whisper_asr_005", "task_type": "speech_recognition", "task_description": "Whisper en ASR on librispeech", "use_case": "Speech recognition - en", "dataset": {"name": "librispeech", "size": 960, "format": "audio", "language": "en"}, "model": {"name": "openai/whisper-large-v2", "size_params": "1.55B", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-large-v2"}, "training_config": {"learning_rate": 5e-06, "batch_size": 4, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "A100", "gpu_memory_gb": 40, "quantization": "none"}, "source": "whisper_official", "tags": ["asr", "speech", "whisper", "en"], "validated": true}
{"id": "whisper_asr_006", "task_type": "speech_recognition", "task_description": "Whisper hi ASR on common_voice", "use_case": "Speech recognition - hi", "dataset": {"name": "common_voice", "size": 30000, "format": "audio", "language": "hi"}, "model": {"name": "openai/whisper-small", "size_params": "244M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-small"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_official", "tags": ["asr", "speech", "whisper", "hi"], "validated": true}
{"id": "whisper_asr_007", "task_type": "speech_recognition", "task_description": "Whisper fr ASR on common_voice", "use_case": "Speech recognition - fr", "dataset": {"name": "common_voice", "size": 30000, "format": "audio", "language": "fr"}, "model": {"name": "openai/whisper-small", "size_params": "244M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-small"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_official", "tags": ["asr", "speech", "whisper", "fr"], "validated": true}
{"id": "whisper_asr_008", "task_type": "speech_recognition", "task_description": "Whisper de ASR on common_voice", "use_case": "Speech recognition - de", "dataset": {"name": "common_voice", "size": 30000, "format": "audio", "language": "de"}, "model": {"name": "openai/whisper-small", "size_params": "244M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-small"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_official", "tags": ["asr", "speech", "whisper", "de"], "validated": true}
{"id": "whisper_asr_009", "task_type": "speech_recognition", "task_description": "Whisper es ASR on common_voice", "use_case": "Speech recognition - es", "dataset": {"name": "common_voice", "size": 30000, "format": "audio", "language": "es"}, "model": {"name": "openai/whisper-base", "size_params": "74M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-base"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_official", "tags": ["asr", "speech", "whisper", "es"], "validated": true}
{"id": "whisper_asr_010", "task_type": "speech_recognition", "task_description": "Whisper ko ASR on korean_asr", "use_case": "Speech recognition - ko", "dataset": {"name": "korean_asr", "size": 30000, "format": "audio", "language": "ko"}, "model": {"name": "openai/whisper-large-v3", "size_params": "1.55B", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-large-v3"}, "training_config": {"learning_rate": 5e-06, "batch_size": 2, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "A100", "gpu_memory_gb": 40, "quantization": "none"}, "source": "whisper_official", "tags": ["asr", "speech", "whisper", "ko"], "validated": true}
{"id": "vision_001", "task_type": "image_classification", "task_description": "Vision transformer on beans", "use_case": "Image classification - beans", "dataset": {"name": "beans", "size": 1034, "format": "image"}, "model": {"name": "google/vit-base-patch16-224", "size_params": "86M", "architecture": "ViTForImageClassification", "hf_hub_id": "google/vit-base-patch16-224"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 4, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "vision_transformers", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vision_002", "task_type": "image_classification", "task_description": "Vision transformer on cifar10", "use_case": "Image classification - cifar10", "dataset": {"name": "cifar10", "size": 50000, "format": "image"}, "model": {"name": "google/vit-base-patch16-224", "size_params": "86M", "architecture": "ViTForImageClassification", "hf_hub_id": "google/vit-base-patch16-224"}, "training_config": {"learning_rate": 0.0003, "num_epochs": 300, "batch_size": 64, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "vision_transformers", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vision_003", "task_type": "image_classification", "task_description": "Vision transformer on food101", "use_case": "Image classification - food101", "dataset": {"name": "food101", "size": 1281167, "format": "image"}, "model": {"name": "google/vit-base-patch16-224", "size_params": "86M", "architecture": "ViTForImageClassification", "hf_hub_id": "google/vit-base-patch16-224"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 300, "batch_size": 32, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "vision_transformers", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vision_004", "task_type": "image_classification", "task_description": "Vision transformer on imagenet", "use_case": "Image classification - imagenet", "dataset": {"name": "imagenet", "size": 1281167, "format": "image"}, "model": {"name": "google/vit-large-patch16-224", "size_params": "304M", "architecture": "ViTForImageClassification", "hf_hub_id": "google/vit-large-patch16-224"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 300, "batch_size": 256, "warmup_steps": 10000}, "hardware_config": {"target_gpu": "V100", "gpu_memory_gb": 32, "quantization": "none"}, "source": "vision_transformers", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vision_005", "task_type": "image_classification", "task_description": "Vision transformer on cifar100", "use_case": "Image classification - cifar100", "dataset": {"name": "cifar100", "size": 50000, "format": "image"}, "model": {"name": "facebook/deit-tiny-patch16-224", "size_params": "5M", "architecture": "DeiTForImageClassification", "hf_hub_id": "facebook/deit-tiny-patch16-224"}, "training_config": {"learning_rate": 0.0005, "num_epochs": 300, "batch_size": 128, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "vision_transformers", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vision_006", "task_type": "image_classification", "task_description": "Vision transformer on imagenet", "use_case": "Image classification - imagenet", "dataset": {"name": "imagenet", "size": 1281167, "format": "image"}, "model": {"name": "facebook/deit-small-patch16-224", "size_params": "22M", "architecture": "DeiTForImageClassification", "hf_hub_id": "facebook/deit-small-patch16-224"}, "training_config": {"learning_rate": 0.001, "num_epochs": 300, "batch_size": 1024, "warmup_steps": 10000}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "vision_transformers", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vision_007", "task_type": "image_classification", "task_description": "Vision transformer on imagenet", "use_case": "Image classification - imagenet", "dataset": {"name": "imagenet", "size": 1281167, "format": "image"}, "model": {"name": "facebook/deit-base-patch16-224", "size_params": "86M", "architecture": "DeiTForImageClassification", "hf_hub_id": "facebook/deit-base-patch16-224"}, "training_config": {"learning_rate": 0.0005, "num_epochs": 300, "batch_size": 1024, "warmup_steps": 10000}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "vision_transformers", "tags": ["vision", "image_classification"], "validated": true}
{"id": "layout_001", "task_type": "document_understanding", "task_description": "Document AI on funsd", "use_case": "Form understanding - funsd", "dataset": {"name": "funsd", "size": 199, "format": "scanned_documents"}, "model": {"name": "microsoft/layoutlm-base-uncased", "size_params": "113M", "architecture": "LayoutLMForTokenClassification", "hf_hub_id": "microsoft/layoutlm-base-uncased"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 50, "batch_size": 16, "warmup_ratio": 0.1}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "microsoft_layoutlm", "tags": ["document_ai", "ocr", "funsd"], "validated": true}
{"id": "layout_002", "task_type": "document_understanding", "task_description": "Document AI on funsd", "use_case": "Form understanding - funsd", "dataset": {"name": "funsd", "size": 199, "format": "scanned_documents"}, "model": {"name": "microsoft/layoutlmv2-base-uncased", "size_params": "200M", "architecture": "LayoutLMForTokenClassification", "hf_hub_id": "microsoft/layoutlmv2-base-uncased"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 100, "batch_size": 2, "warmup_ratio": 0.1}, "hardware_config": {"target_gpu": "V100", "gpu_memory_gb": 16, "quantization": "none"}, "source": "microsoft_layoutlm", "tags": ["document_ai", "ocr", "funsd"], "validated": true}
{"id": "layout_003", "task_type": "document_understanding", "task_description": "Document AI on docvqa", "use_case": "Form understanding - docvqa", "dataset": {"name": "docvqa", "size": 10000, "format": "scanned_documents"}, "model": {"name": "microsoft/layoutlmv2-base-uncased", "size_params": "200M", "architecture": "LayoutLMForTokenClassification", "hf_hub_id": "microsoft/layoutlmv2-base-uncased"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 20, "batch_size": 1, "warmup_ratio": 0.1}, "hardware_config": {"target_gpu": "V100", "gpu_memory_gb": 16, "quantization": "none"}, "source": "microsoft_layoutlm", "tags": ["document_ai", "ocr", "docvqa"], "validated": true}
{"id": "layout_004", "task_type": "document_understanding", "task_description": "Document AI on funsd", "use_case": "Form understanding - funsd", "dataset": {"name": "funsd", "size": 199, "format": "scanned_documents"}, "model": {"name": "microsoft/layoutlmv3-base", "size_params": "125M", "architecture": "LayoutLMForTokenClassification", "hf_hub_id": "microsoft/layoutlmv3-base"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 100, "batch_size": 16, "warmup_ratio": 0.1}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "microsoft_layoutlm", "tags": ["document_ai", "ocr", "funsd"], "validated": true}
{"id": "layout_005", "task_type": "document_understanding", "task_description": "Document AI on rvl-cdip", "use_case": "Form understanding - rvl-cdip", "dataset": {"name": "rvl-cdip", "size": 320000, "format": "scanned_documents"}, "model": {"name": "microsoft/layoutlmv3-base", "size_params": "125M", "architecture": "LayoutLMForTokenClassification", "hf_hub_id": "microsoft/layoutlmv3-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 30, "batch_size": 32, "warmup_ratio": 0.1}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "microsoft_layoutlm", "tags": ["document_ai", "ocr", "rvl-cdip"], "validated": true}
{"id": "trocr_001", "task_type": "optical_character_recognition", "task_description": "TrOCR text recognition on iam", "use_case": "Text extraction from images", "dataset": {"name": "iam", "size": 115000, "format": "image_text_pairs"}, "model": {"name": "microsoft/trocr-small-handwritten", "size_params": "62M", "architecture": "VisionEncoderDecoderModel", "hf_hub_id": "microsoft/trocr-small-handwritten"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 10, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "microsoft_trocr", "tags": ["ocr", "trocr", "iam"], "validated": true}
{"id": "trocr_002", "task_type": "optical_character_recognition", "task_description": "TrOCR text recognition on iam", "use_case": "Text extraction from images", "dataset": {"name": "iam", "size": 115000, "format": "image_text_pairs"}, "model": {"name": "microsoft/trocr-base-handwritten", "size_params": "334M", "architecture": "VisionEncoderDecoderModel", "hf_hub_id": "microsoft/trocr-base-handwritten"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 10, "batch_size": 4, "warmup_steps": 500}, "hardware_config": {"target_gpu": "V100", "gpu_memory_gb": 16, "quantization": "none"}, "source": "microsoft_trocr", "tags": ["ocr", "trocr", "iam"], "validated": true}
{"id": "trocr_003", "task_type": "optical_character_recognition", "task_description": "TrOCR text recognition on iam", "use_case": "Text extraction from images", "dataset": {"name": "iam", "size": 115000, "format": "image_text_pairs"}, "model": {"name": "microsoft/trocr-large-handwritten", "size_params": "558M", "architecture": "VisionEncoderDecoderModel", "hf_hub_id": "microsoft/trocr-large-handwritten"}, "training_config": {"learning_rate": 3e-05, "num_epochs": 10, "batch_size": 2, "warmup_steps": 500}, "hardware_config": {"target_gpu": "A100", "gpu_memory_gb": 40, "quantization": "none"}, "source": "microsoft_trocr", "tags": ["ocr", "trocr", "iam"], "validated": true}
{"id": "trocr_004", "task_type": "optical_character_recognition", "task_description": "TrOCR text recognition on sroie", "use_case": "Text extraction from images", "dataset": {"name": "sroie", "size": 626, "format": "image_text_pairs"}, "model": {"name": "microsoft/trocr-small-printed", "size_params": "62M", "architecture": "VisionEncoderDecoderModel", "hf_hub_id": "microsoft/trocr-small-printed"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 40, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "microsoft_trocr", "tags": ["ocr", "trocr", "sroie"], "validated": true}
{"id": "trocr_005", "task_type": "optical_character_recognition", "task_description": "TrOCR text recognition on sroie", "use_case": "Text extraction from images", "dataset": {"name": "sroie", "size": 626, "format": "image_text_pairs"}, "model": {"name": "microsoft/trocr-base-printed", "size_params": "334M", "architecture": "VisionEncoderDecoderModel", "hf_hub_id": "microsoft/trocr-base-printed"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 40, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "V100", "gpu_memory_gb": 16, "quantization": "none"}, "source": "microsoft_trocr", "tags": ["ocr", "trocr", "sroie"], "validated": true}
{"id": "multilingual_001", "task_type": "ner", "task_description": "Multilingual ner on wikiann", "use_case": "Cross-lingual ner", "dataset": {"name": "wikiann", "size": 20000, "format": "hf_dataset", "language": "multi"}, "model": {"name": "bert-base-multilingual-cased", "size_params": "180M", "architecture": "BertForTokenClassification", "hf_hub_id": "bert-base-multilingual-cased"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 32, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "multilingual_baselines", "tags": ["multilingual", "multi", "ner"], "validated": true}
{"id": "multilingual_002", "task_type": "classification", "task_description": "Multilingual classification on xnli", "use_case": "Cross-lingual classification", "dataset": {"name": "xnli", "size": 392702, "format": "hf_dataset", "language": "multi"}, "model": {"name": "xlm-roberta-base", "size_params": "270M", "architecture": "BertForSequenceClassification", "hf_hub_id": "xlm-roberta-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 32, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "multilingual_baselines", "tags": ["multilingual", "multi", "classification"], "validated": true}
{"id": "multilingual_003", "task_type": "ner", "task_description": "Multilingual ner on wikiann", "use_case": "Cross-lingual ner", "dataset": {"name": "wikiann", "size": 20000, "format": "hf_dataset", "language": "multi"}, "model": {"name": "xlm-roberta-base", "size_params": "270M", "architecture": "BertForTokenClassification", "hf_hub_id": "xlm-roberta-base"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 32, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "multilingual_baselines", "tags": ["multilingual", "multi", "ner"], "validated": true}
{"id": "multilingual_004", "task_type": "classification", "task_description": "Multilingual classification on xnli", "use_case": "Cross-lingual classification", "dataset": {"name": "xnli", "size": 392702, "format": "hf_dataset", "language": "multi"}, "model": {"name": "xlm-roberta-large", "size_params": "550M", "architecture": "BertForSequenceClassification", "hf_hub_id": "xlm-roberta-large"}, "training_config": {"learning_rate": 1e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "V100", "gpu_memory_gb": 32, "quantization": "none"}, "source": "multilingual_baselines", "tags": ["multilingual", "multi", "classification"], "validated": true}
{"id": "multilingual_005", "task_type": "ner", "task_description": "Multilingual ner on germeval", "use_case": "Cross-lingual ner", "dataset": {"name": "germeval", "size": 20000, "format": "hf_dataset", "language": "de"}, "model": {"name": "dbmdz/bert-base-german-cased", "size_params": "110M", "architecture": "BertForTokenClassification", "hf_hub_id": "dbmdz/bert-base-german-cased"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 32, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "multilingual_baselines", "tags": ["multilingual", "de", "ner"], "validated": true}
{"id": "translation_001", "task_type": "translation", "task_description": "Translation en to de", "use_case": "Machine translation - en to de", "dataset": {"name": "wmt14", "size": 4500000, "format": "parallel_corpus", "source_lang": "en", "target_lang": "de"}, "model": {"name": "google/mt5-small", "size_params": "300M", "architecture": "MT5ForConditionalGeneration", "hf_hub_id": "google/mt5-small"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 32, "warmup_steps": 1000}, "hardware_config": {"target_gpu": "V100", "gpu_memory_gb": 40, "quantization": "none"}, "source": "translation_models", "tags": ["translation", "en", "de"], "validated": true}
{"id": "translation_002", "task_type": "translation", "task_description": "Translation en to fr", "use_case": "Machine translation - en to fr", "dataset": {"name": "wmt14", "size": 4500000, "format": "parallel_corpus", "source_lang": "en", "target_lang": "fr"}, "model": {"name": "google/mt5-base", "size_params": "580M", "architecture": "MT5ForConditionalGeneration", "hf_hub_id": "google/mt5-base"}, "training_config": {"learning_rate": 3e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 1000}, "hardware_config": {"target_gpu": "A100", "gpu_memory_gb": 40, "quantization": "none"}, "source": "translation_models", "tags": ["translation", "en", "fr"], "validated": true}
{"id": "translation_003", "task_type": "translation", "task_description": "Translation en to de", "use_case": "Machine translation - en to de", "dataset": {"name": "wmt14", "size": 4500000, "format": "parallel_corpus", "source_lang": "en", "target_lang": "de"}, "model": {"name": "facebook/mbart-large-50", "size_params": "680M", "architecture": "MBartForConditionalGeneration", "hf_hub_id": "facebook/mbart-large-50"}, "training_config": {"learning_rate": 3e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 1000}, "hardware_config": {"target_gpu": "A100", "gpu_memory_gb": 40, "quantization": "none"}, "source": "translation_models", "tags": ["translation", "en", "de"], "validated": true}
{"id": "translation_004", "task_type": "translation", "task_description": "Translation en to es", "use_case": "Machine translation - en to es", "dataset": {"name": "wmt14", "size": 4500000, "format": "parallel_corpus", "source_lang": "en", "target_lang": "es"}, "model": {"name": "facebook/m2m100_418M", "size_params": "418M", "architecture": "M2M100ForConditionalGeneration", "hf_hub_id": "facebook/m2m100_418M"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 1000}, "hardware_config": {"target_gpu": "V100", "gpu_memory_gb": 40, "quantization": "none"}, "source": "translation_models", "tags": ["translation", "en", "es"], "validated": true}
{"id": "code_001", "task_type": "code_generation", "task_description": "Code generation for Python", "use_case": "Code completion and generation", "dataset": {"name": "python_code_instructions", "size": 18000, "format": "hf_dataset"}, "model": {"name": "codellama/CodeLlama-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "codellama/CodeLlama-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 16, "lora_alpha": 32, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "code_generation", "tags": ["code", "python"], "validated": true}
{"id": "code_002", "task_type": "code_generation", "task_description": "Code generation for Python", "use_case": "Code completion and generation", "dataset": {"name": "code_alpaca", "size": 18000, "format": "hf_dataset"}, "model": {"name": "Salesforce/codegen-350M-mono", "size_params": "350M", "architecture": "GPTNeoForCausalLM", "hf_hub_id": "Salesforce/codegen-350M-mono"}, "adapter": "lora", "lora_config": {"r": 16, "lora_alpha": 32, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0003, "num_epochs": 3, "batch_size": 8, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "code_generation", "tags": ["code", "python"], "validated": true}
{"id": "code_003", "task_type": "code_generation", "task_description": "Code generation for Python", "use_case": "Code completion and generation", "dataset": {"name": "code_alpaca", "size": 18000, "format": "hf_dataset"}, "model": {"name": "bigcode/starcoderbase-1b", "size_params": "1B", "architecture": "GPTNeoForCausalLM", "hf_hub_id": "bigcode/starcoderbase-1b"}, "adapter": "lora", "lora_config": {"r": 16, "lora_alpha": 32, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 8, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "code_generation", "tags": ["code", "python"], "validated": true}
{"id": "bert_var_001", "task_type": "classification", "task_description": "BERT classification variant on imdb", "use_case": "Text classification - imdb", "dataset": {"name": "imdb", "size": 25000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 1e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "imdb"], "validated": true}
{"id": "bert_var_002", "task_type": "classification", "task_description": "BERT classification variant on sst2", "use_case": "Text classification - sst2", "dataset": {"name": "sst2", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "sst2"], "validated": true}
{"id": "bert_var_003", "task_type": "classification", "task_description": "BERT classification variant on ag_news", "use_case": "Text classification - ag_news", "dataset": {"name": "ag_news", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 3e-05, "num_epochs": 3, "batch_size": 32, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "ag_news"], "validated": true}
{"id": "bert_var_004", "task_type": "classification", "task_description": "BERT classification variant on yelp_polarity", "use_case": "Text classification - yelp_polarity", "dataset": {"name": "yelp_polarity", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "yelp_polarity"], "validated": true}
{"id": "bert_var_005", "task_type": "classification", "task_description": "BERT classification variant on tweet_eval", "use_case": "Text classification - tweet_eval", "dataset": {"name": "tweet_eval", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 0.0001, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "tweet_eval"], "validated": true}
{"id": "bert_var_006", "task_type": "classification", "task_description": "BERT classification variant on rotten_tomatoes", "use_case": "Text classification - rotten_tomatoes", "dataset": {"name": "rotten_tomatoes", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 32, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "rotten_tomatoes"], "validated": true}
{"id": "bert_var_007", "task_type": "classification", "task_description": "BERT classification variant on imdb", "use_case": "Text classification - imdb", "dataset": {"name": "imdb", "size": 25000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 1e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "imdb"], "validated": true}
{"id": "bert_var_008", "task_type": "classification", "task_description": "BERT classification variant on sst2", "use_case": "Text classification - sst2", "dataset": {"name": "sst2", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "sst2"], "validated": true}
{"id": "bert_var_009", "task_type": "classification", "task_description": "BERT classification variant on ag_news", "use_case": "Text classification - ag_news", "dataset": {"name": "ag_news", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 3e-05, "num_epochs": 3, "batch_size": 32, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "ag_news"], "validated": true}
{"id": "bert_var_010", "task_type": "classification", "task_description": "BERT classification variant on yelp_polarity", "use_case": "Text classification - yelp_polarity", "dataset": {"name": "yelp_polarity", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "yelp_polarity"], "validated": true}
{"id": "bert_var_011", "task_type": "classification", "task_description": "BERT classification variant on tweet_eval", "use_case": "Text classification - tweet_eval", "dataset": {"name": "tweet_eval", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 0.0001, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "tweet_eval"], "validated": true}
{"id": "bert_var_012", "task_type": "classification", "task_description": "BERT classification variant on rotten_tomatoes", "use_case": "Text classification - rotten_tomatoes", "dataset": {"name": "rotten_tomatoes", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 32, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "rotten_tomatoes"], "validated": true}
{"id": "bert_var_013", "task_type": "classification", "task_description": "BERT classification variant on imdb", "use_case": "Text classification - imdb", "dataset": {"name": "imdb", "size": 25000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 1e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "imdb"], "validated": true}
{"id": "bert_var_014", "task_type": "classification", "task_description": "BERT classification variant on sst2", "use_case": "Text classification - sst2", "dataset": {"name": "sst2", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "sst2"], "validated": true}
{"id": "bert_var_015", "task_type": "classification", "task_description": "BERT classification variant on ag_news", "use_case": "Text classification - ag_news", "dataset": {"name": "ag_news", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 3e-05, "num_epochs": 3, "batch_size": 32, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "ag_news"], "validated": true}
{"id": "bert_var_016", "task_type": "classification", "task_description": "BERT classification variant on yelp_polarity", "use_case": "Text classification - yelp_polarity", "dataset": {"name": "yelp_polarity", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "yelp_polarity"], "validated": true}
{"id": "bert_var_017", "task_type": "classification", "task_description": "BERT classification variant on tweet_eval", "use_case": "Text classification - tweet_eval", "dataset": {"name": "tweet_eval", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 0.0001, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "tweet_eval"], "validated": true}
{"id": "bert_var_018", "task_type": "classification", "task_description": "BERT classification variant on rotten_tomatoes", "use_case": "Text classification - rotten_tomatoes", "dataset": {"name": "rotten_tomatoes", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 32, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "rotten_tomatoes"], "validated": true}
{"id": "bert_var_019", "task_type": "classification", "task_description": "BERT classification variant on imdb", "use_case": "Text classification - imdb", "dataset": {"name": "imdb", "size": 25000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 1e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "imdb"], "validated": true}
{"id": "bert_var_020", "task_type": "classification", "task_description": "BERT classification variant on sst2", "use_case": "Text classification - sst2", "dataset": {"name": "sst2", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "sst2"], "validated": true}
{"id": "bert_var_021", "task_type": "classification", "task_description": "BERT classification variant on ag_news", "use_case": "Text classification - ag_news", "dataset": {"name": "ag_news", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 3e-05, "num_epochs": 3, "batch_size": 32, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "ag_news"], "validated": true}
{"id": "bert_var_022", "task_type": "classification", "task_description": "BERT classification variant on yelp_polarity", "use_case": "Text classification - yelp_polarity", "dataset": {"name": "yelp_polarity", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "yelp_polarity"], "validated": true}
{"id": "bert_var_023", "task_type": "classification", "task_description": "BERT classification variant on tweet_eval", "use_case": "Text classification - tweet_eval", "dataset": {"name": "tweet_eval", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 0.0001, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "tweet_eval"], "validated": true}
{"id": "bert_var_024", "task_type": "classification", "task_description": "BERT classification variant on rotten_tomatoes", "use_case": "Text classification - rotten_tomatoes", "dataset": {"name": "rotten_tomatoes", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 32, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "rotten_tomatoes"], "validated": true}
{"id": "bert_var_025", "task_type": "classification", "task_description": "BERT classification variant on imdb", "use_case": "Text classification - imdb", "dataset": {"name": "imdb", "size": 25000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 1e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "imdb"], "validated": true}
{"id": "bert_var_026", "task_type": "classification", "task_description": "BERT classification variant on sst2", "use_case": "Text classification - sst2", "dataset": {"name": "sst2", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "sst2"], "validated": true}
{"id": "bert_var_027", "task_type": "classification", "task_description": "BERT classification variant on ag_news", "use_case": "Text classification - ag_news", "dataset": {"name": "ag_news", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 3e-05, "num_epochs": 3, "batch_size": 32, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "ag_news"], "validated": true}
{"id": "bert_var_028", "task_type": "classification", "task_description": "BERT classification variant on yelp_polarity", "use_case": "Text classification - yelp_polarity", "dataset": {"name": "yelp_polarity", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "yelp_polarity"], "validated": true}
{"id": "bert_var_029", "task_type": "classification", "task_description": "BERT classification variant on tweet_eval", "use_case": "Text classification - tweet_eval", "dataset": {"name": "tweet_eval", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 0.0001, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "tweet_eval"], "validated": true}
{"id": "bert_var_030", "task_type": "classification", "task_description": "BERT classification variant on rotten_tomatoes", "use_case": "Text classification - rotten_tomatoes", "dataset": {"name": "rotten_tomatoes", "size": 50000, "format": "hf_dataset"}, "model": {"name": "bert-base-uncased", "size_params": "110M", "architecture": "BertForSequenceClassification", "hf_hub_id": "bert-base-uncased"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 32, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "bert_variations", "tags": ["classification", "bert", "rotten_tomatoes"], "validated": true}
{"id": "llama_var_001", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=8 on guanaco-llama2-1k", "use_case": "Instruction-following chatbot", "dataset": {"name": "guanaco-llama2-1k", "size": 1000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 8, "lora_alpha": 16, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_002", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=16 on openassistant-guanaco", "use_case": "Instruction-following chatbot", "dataset": {"name": "openassistant-guanaco", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 16, "lora_alpha": 32, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_003", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=32 on alpaca-cleaned", "use_case": "Instruction-following chatbot", "dataset": {"name": "alpaca-cleaned", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 32, "lora_alpha": 64, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_004", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=64 on dolly-15k", "use_case": "Instruction-following chatbot", "dataset": {"name": "dolly-15k", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 64, "lora_alpha": 128, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_005", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=8 on guanaco-llama2-1k", "use_case": "Instruction-following chatbot", "dataset": {"name": "guanaco-llama2-1k", "size": 1000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 8, "lora_alpha": 16, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_006", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=16 on openassistant-guanaco", "use_case": "Instruction-following chatbot", "dataset": {"name": "openassistant-guanaco", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 16, "lora_alpha": 32, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_007", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=32 on alpaca-cleaned", "use_case": "Instruction-following chatbot", "dataset": {"name": "alpaca-cleaned", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 32, "lora_alpha": 64, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_008", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=64 on dolly-15k", "use_case": "Instruction-following chatbot", "dataset": {"name": "dolly-15k", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 64, "lora_alpha": 128, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_009", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=8 on guanaco-llama2-1k", "use_case": "Instruction-following chatbot", "dataset": {"name": "guanaco-llama2-1k", "size": 1000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 8, "lora_alpha": 16, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_010", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=16 on openassistant-guanaco", "use_case": "Instruction-following chatbot", "dataset": {"name": "openassistant-guanaco", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 16, "lora_alpha": 32, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_011", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=32 on alpaca-cleaned", "use_case": "Instruction-following chatbot", "dataset": {"name": "alpaca-cleaned", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 32, "lora_alpha": 64, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_012", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=64 on dolly-15k", "use_case": "Instruction-following chatbot", "dataset": {"name": "dolly-15k", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 64, "lora_alpha": 128, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_013", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=8 on guanaco-llama2-1k", "use_case": "Instruction-following chatbot", "dataset": {"name": "guanaco-llama2-1k", "size": 1000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 8, "lora_alpha": 16, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_014", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=16 on openassistant-guanaco", "use_case": "Instruction-following chatbot", "dataset": {"name": "openassistant-guanaco", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 16, "lora_alpha": 32, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_015", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=32 on alpaca-cleaned", "use_case": "Instruction-following chatbot", "dataset": {"name": "alpaca-cleaned", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 32, "lora_alpha": 64, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_016", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=64 on dolly-15k", "use_case": "Instruction-following chatbot", "dataset": {"name": "dolly-15k", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 64, "lora_alpha": 128, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_017", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=8 on guanaco-llama2-1k", "use_case": "Instruction-following chatbot", "dataset": {"name": "guanaco-llama2-1k", "size": 1000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 8, "lora_alpha": 16, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_018", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=16 on openassistant-guanaco", "use_case": "Instruction-following chatbot", "dataset": {"name": "openassistant-guanaco", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 16, "lora_alpha": 32, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_019", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=32 on alpaca-cleaned", "use_case": "Instruction-following chatbot", "dataset": {"name": "alpaca-cleaned", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 32, "lora_alpha": 64, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_020", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=64 on dolly-15k", "use_case": "Instruction-following chatbot", "dataset": {"name": "dolly-15k", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 64, "lora_alpha": 128, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_021", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=8 on guanaco-llama2-1k", "use_case": "Instruction-following chatbot", "dataset": {"name": "guanaco-llama2-1k", "size": 1000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 8, "lora_alpha": 16, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_022", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=16 on openassistant-guanaco", "use_case": "Instruction-following chatbot", "dataset": {"name": "openassistant-guanaco", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 16, "lora_alpha": 32, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_023", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=32 on alpaca-cleaned", "use_case": "Instruction-following chatbot", "dataset": {"name": "alpaca-cleaned", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 32, "lora_alpha": 64, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_024", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=64 on dolly-15k", "use_case": "Instruction-following chatbot", "dataset": {"name": "dolly-15k", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 64, "lora_alpha": 128, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_025", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=8 on guanaco-llama2-1k", "use_case": "Instruction-following chatbot", "dataset": {"name": "guanaco-llama2-1k", "size": 1000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 8, "lora_alpha": 16, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_026", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=16 on openassistant-guanaco", "use_case": "Instruction-following chatbot", "dataset": {"name": "openassistant-guanaco", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 16, "lora_alpha": 32, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_027", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=32 on alpaca-cleaned", "use_case": "Instruction-following chatbot", "dataset": {"name": "alpaca-cleaned", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 32, "lora_alpha": 64, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_028", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=64 on dolly-15k", "use_case": "Instruction-following chatbot", "dataset": {"name": "dolly-15k", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 64, "lora_alpha": 128, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_029", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=8 on guanaco-llama2-1k", "use_case": "Instruction-following chatbot", "dataset": {"name": "guanaco-llama2-1k", "size": 1000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 8, "lora_alpha": 16, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_030", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=16 on openassistant-guanaco", "use_case": "Instruction-following chatbot", "dataset": {"name": "openassistant-guanaco", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 16, "lora_alpha": 32, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_031", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=32 on alpaca-cleaned", "use_case": "Instruction-following chatbot", "dataset": {"name": "alpaca-cleaned", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 32, "lora_alpha": 64, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_032", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=64 on dolly-15k", "use_case": "Instruction-following chatbot", "dataset": {"name": "dolly-15k", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 64, "lora_alpha": 128, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_033", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=8 on guanaco-llama2-1k", "use_case": "Instruction-following chatbot", "dataset": {"name": "guanaco-llama2-1k", "size": 1000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 8, "lora_alpha": 16, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_034", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=16 on openassistant-guanaco", "use_case": "Instruction-following chatbot", "dataset": {"name": "openassistant-guanaco", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 16, "lora_alpha": 32, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_035", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=32 on alpaca-cleaned", "use_case": "Instruction-following chatbot", "dataset": {"name": "alpaca-cleaned", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 32, "lora_alpha": 64, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_036", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=64 on dolly-15k", "use_case": "Instruction-following chatbot", "dataset": {"name": "dolly-15k", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 64, "lora_alpha": 128, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_037", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=8 on guanaco-llama2-1k", "use_case": "Instruction-following chatbot", "dataset": {"name": "guanaco-llama2-1k", "size": 1000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 8, "lora_alpha": 16, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_038", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=16 on openassistant-guanaco", "use_case": "Instruction-following chatbot", "dataset": {"name": "openassistant-guanaco", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 16, "lora_alpha": 32, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_039", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=32 on alpaca-cleaned", "use_case": "Instruction-following chatbot", "dataset": {"name": "alpaca-cleaned", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 32, "lora_alpha": 64, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "llama_var_040", "task_type": "chatbot", "task_description": "Llama-2 QLoRA r=64 on dolly-15k", "use_case": "Instruction-following chatbot", "dataset": {"name": "dolly-15k", "size": 15000, "format": "hf_dataset"}, "model": {"name": "meta-llama/Llama-2-7b-hf", "size_params": "7B", "architecture": "LlamaForCausalLM", "hf_hub_id": "meta-llama/Llama-2-7b-hf"}, "adapter": "qlora", "lora_config": {"r": 64, "lora_alpha": 128, "lora_dropout": 0.1, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 1, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "llama_variations", "tags": ["chatbot", "llama2", "qlora"], "validated": true}
{"id": "summ_var_001", "task_type": "summarization", "task_description": "t5-small on cnn_dailymail", "use_case": "Summarization - cnn_dailymail", "dataset": {"name": "cnn_dailymail", "size": 287000, "format": "hf_dataset"}, "model": {"name": "t5-small", "size_params": "60M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-small"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "cnn_dailymail"], "validated": true}
{"id": "summ_var_002", "task_type": "summarization", "task_description": "t5-base on xsum", "use_case": "Summarization - xsum", "dataset": {"name": "xsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "t5-base", "size_params": "220M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "xsum"], "validated": true}
{"id": "summ_var_003", "task_type": "summarization", "task_description": "facebook/bart-base on samsum", "use_case": "Summarization - samsum", "dataset": {"name": "samsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "facebook/bart-base", "size_params": "220M", "architecture": "BartForConditionalGeneration", "hf_hub_id": "facebook/bart-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "samsum"], "validated": true}
{"id": "summ_var_004", "task_type": "summarization", "task_description": "facebook/bart-large on billsum", "use_case": "Summarization - billsum", "dataset": {"name": "billsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "facebook/bart-large", "size_params": "406M", "architecture": "BartForConditionalGeneration", "hf_hub_id": "facebook/bart-large"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "V100", "gpu_memory_gb": 32, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "billsum"], "validated": true}
{"id": "summ_var_005", "task_type": "summarization", "task_description": "t5-small on cnn_dailymail", "use_case": "Summarization - cnn_dailymail", "dataset": {"name": "cnn_dailymail", "size": 287000, "format": "hf_dataset"}, "model": {"name": "t5-small", "size_params": "60M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-small"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "cnn_dailymail"], "validated": true}
{"id": "summ_var_006", "task_type": "summarization", "task_description": "t5-base on xsum", "use_case": "Summarization - xsum", "dataset": {"name": "xsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "t5-base", "size_params": "220M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "xsum"], "validated": true}
{"id": "summ_var_007", "task_type": "summarization", "task_description": "facebook/bart-base on samsum", "use_case": "Summarization - samsum", "dataset": {"name": "samsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "facebook/bart-base", "size_params": "220M", "architecture": "BartForConditionalGeneration", "hf_hub_id": "facebook/bart-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "samsum"], "validated": true}
{"id": "summ_var_008", "task_type": "summarization", "task_description": "facebook/bart-large on billsum", "use_case": "Summarization - billsum", "dataset": {"name": "billsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "facebook/bart-large", "size_params": "406M", "architecture": "BartForConditionalGeneration", "hf_hub_id": "facebook/bart-large"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "V100", "gpu_memory_gb": 32, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "billsum"], "validated": true}
{"id": "summ_var_009", "task_type": "summarization", "task_description": "t5-small on cnn_dailymail", "use_case": "Summarization - cnn_dailymail", "dataset": {"name": "cnn_dailymail", "size": 287000, "format": "hf_dataset"}, "model": {"name": "t5-small", "size_params": "60M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-small"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "cnn_dailymail"], "validated": true}
{"id": "summ_var_010", "task_type": "summarization", "task_description": "t5-base on xsum", "use_case": "Summarization - xsum", "dataset": {"name": "xsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "t5-base", "size_params": "220M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "xsum"], "validated": true}
{"id": "summ_var_011", "task_type": "summarization", "task_description": "facebook/bart-base on samsum", "use_case": "Summarization - samsum", "dataset": {"name": "samsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "facebook/bart-base", "size_params": "220M", "architecture": "BartForConditionalGeneration", "hf_hub_id": "facebook/bart-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "samsum"], "validated": true}
{"id": "summ_var_012", "task_type": "summarization", "task_description": "facebook/bart-large on billsum", "use_case": "Summarization - billsum", "dataset": {"name": "billsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "facebook/bart-large", "size_params": "406M", "architecture": "BartForConditionalGeneration", "hf_hub_id": "facebook/bart-large"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "V100", "gpu_memory_gb": 32, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "billsum"], "validated": true}
{"id": "summ_var_013", "task_type": "summarization", "task_description": "t5-small on cnn_dailymail", "use_case": "Summarization - cnn_dailymail", "dataset": {"name": "cnn_dailymail", "size": 287000, "format": "hf_dataset"}, "model": {"name": "t5-small", "size_params": "60M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-small"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "cnn_dailymail"], "validated": true}
{"id": "summ_var_014", "task_type": "summarization", "task_description": "t5-base on xsum", "use_case": "Summarization - xsum", "dataset": {"name": "xsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "t5-base", "size_params": "220M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "xsum"], "validated": true}
{"id": "summ_var_015", "task_type": "summarization", "task_description": "facebook/bart-base on samsum", "use_case": "Summarization - samsum", "dataset": {"name": "samsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "facebook/bart-base", "size_params": "220M", "architecture": "BartForConditionalGeneration", "hf_hub_id": "facebook/bart-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "samsum"], "validated": true}
{"id": "summ_var_016", "task_type": "summarization", "task_description": "facebook/bart-large on billsum", "use_case": "Summarization - billsum", "dataset": {"name": "billsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "facebook/bart-large", "size_params": "406M", "architecture": "BartForConditionalGeneration", "hf_hub_id": "facebook/bart-large"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "V100", "gpu_memory_gb": 32, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "billsum"], "validated": true}
{"id": "summ_var_017", "task_type": "summarization", "task_description": "t5-small on cnn_dailymail", "use_case": "Summarization - cnn_dailymail", "dataset": {"name": "cnn_dailymail", "size": 287000, "format": "hf_dataset"}, "model": {"name": "t5-small", "size_params": "60M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-small"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "cnn_dailymail"], "validated": true}
{"id": "summ_var_018", "task_type": "summarization", "task_description": "t5-base on xsum", "use_case": "Summarization - xsum", "dataset": {"name": "xsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "t5-base", "size_params": "220M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "xsum"], "validated": true}
{"id": "summ_var_019", "task_type": "summarization", "task_description": "facebook/bart-base on samsum", "use_case": "Summarization - samsum", "dataset": {"name": "samsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "facebook/bart-base", "size_params": "220M", "architecture": "BartForConditionalGeneration", "hf_hub_id": "facebook/bart-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "samsum"], "validated": true}
{"id": "summ_var_020", "task_type": "summarization", "task_description": "facebook/bart-large on billsum", "use_case": "Summarization - billsum", "dataset": {"name": "billsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "facebook/bart-large", "size_params": "406M", "architecture": "BartForConditionalGeneration", "hf_hub_id": "facebook/bart-large"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "V100", "gpu_memory_gb": 32, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "billsum"], "validated": true}
{"id": "summ_var_021", "task_type": "summarization", "task_description": "t5-small on cnn_dailymail", "use_case": "Summarization - cnn_dailymail", "dataset": {"name": "cnn_dailymail", "size": 287000, "format": "hf_dataset"}, "model": {"name": "t5-small", "size_params": "60M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-small"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "cnn_dailymail"], "validated": true}
{"id": "summ_var_022", "task_type": "summarization", "task_description": "t5-base on xsum", "use_case": "Summarization - xsum", "dataset": {"name": "xsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "t5-base", "size_params": "220M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "xsum"], "validated": true}
{"id": "summ_var_023", "task_type": "summarization", "task_description": "facebook/bart-base on samsum", "use_case": "Summarization - samsum", "dataset": {"name": "samsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "facebook/bart-base", "size_params": "220M", "architecture": "BartForConditionalGeneration", "hf_hub_id": "facebook/bart-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "samsum"], "validated": true}
{"id": "summ_var_024", "task_type": "summarization", "task_description": "facebook/bart-large on billsum", "use_case": "Summarization - billsum", "dataset": {"name": "billsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "facebook/bart-large", "size_params": "406M", "architecture": "BartForConditionalGeneration", "hf_hub_id": "facebook/bart-large"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "V100", "gpu_memory_gb": 32, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "billsum"], "validated": true}
{"id": "summ_var_025", "task_type": "summarization", "task_description": "t5-small on cnn_dailymail", "use_case": "Summarization - cnn_dailymail", "dataset": {"name": "cnn_dailymail", "size": 287000, "format": "hf_dataset"}, "model": {"name": "t5-small", "size_params": "60M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-small"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "cnn_dailymail"], "validated": true}
{"id": "summ_var_026", "task_type": "summarization", "task_description": "t5-base on xsum", "use_case": "Summarization - xsum", "dataset": {"name": "xsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "t5-base", "size_params": "220M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "xsum"], "validated": true}
{"id": "summ_var_027", "task_type": "summarization", "task_description": "facebook/bart-base on samsum", "use_case": "Summarization - samsum", "dataset": {"name": "samsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "facebook/bart-base", "size_params": "220M", "architecture": "BartForConditionalGeneration", "hf_hub_id": "facebook/bart-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "samsum"], "validated": true}
{"id": "summ_var_028", "task_type": "summarization", "task_description": "facebook/bart-large on billsum", "use_case": "Summarization - billsum", "dataset": {"name": "billsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "facebook/bart-large", "size_params": "406M", "architecture": "BartForConditionalGeneration", "hf_hub_id": "facebook/bart-large"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "V100", "gpu_memory_gb": 32, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "billsum"], "validated": true}
{"id": "summ_var_029", "task_type": "summarization", "task_description": "t5-small on cnn_dailymail", "use_case": "Summarization - cnn_dailymail", "dataset": {"name": "cnn_dailymail", "size": 287000, "format": "hf_dataset"}, "model": {"name": "t5-small", "size_params": "60M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-small"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "cnn_dailymail"], "validated": true}
{"id": "summ_var_030", "task_type": "summarization", "task_description": "t5-base on xsum", "use_case": "Summarization - xsum", "dataset": {"name": "xsum", "size": 14700, "format": "hf_dataset"}, "model": {"name": "t5-base", "size_params": "220M", "architecture": "T5ForConditionalGeneration", "hf_hub_id": "t5-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "summarization_variations", "tags": ["summarization", "xsum"], "validated": true}
{"id": "whisper_var_001", "task_type": "speech_recognition", "task_description": "Whisper en ASR", "use_case": "Speech recognition - en", "dataset": {"name": "librispeech", "size": 10000, "format": "audio", "language": "en"}, "model": {"name": "openai/whisper-tiny", "size_params": "39M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-tiny"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "en"], "validated": true}
{"id": "whisper_var_002", "task_type": "speech_recognition", "task_description": "Whisper hi ASR", "use_case": "Speech recognition - hi", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "hi"}, "model": {"name": "openai/whisper-base", "size_params": "74M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-base"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "hi"], "validated": true}
{"id": "whisper_var_003", "task_type": "speech_recognition", "task_description": "Whisper fr ASR", "use_case": "Speech recognition - fr", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "fr"}, "model": {"name": "openai/whisper-small", "size_params": "244M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-small"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "fr"], "validated": true}
{"id": "whisper_var_004", "task_type": "speech_recognition", "task_description": "Whisper de ASR", "use_case": "Speech recognition - de", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "de"}, "model": {"name": "openai/whisper-medium", "size_params": "769M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-medium"}, "training_config": {"learning_rate": 5e-06, "batch_size": 8, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "A100", "gpu_memory_gb": 40, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "de"], "validated": true}
{"id": "whisper_var_005", "task_type": "speech_recognition", "task_description": "Whisper es ASR", "use_case": "Speech recognition - es", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "es"}, "model": {"name": "openai/whisper-tiny", "size_params": "39M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-tiny"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "es"], "validated": true}
{"id": "whisper_var_006", "task_type": "speech_recognition", "task_description": "Whisper ko ASR", "use_case": "Speech recognition - ko", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "ko"}, "model": {"name": "openai/whisper-base", "size_params": "74M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-base"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "ko"], "validated": true}
{"id": "whisper_var_007", "task_type": "speech_recognition", "task_description": "Whisper zh ASR", "use_case": "Speech recognition - zh", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "zh"}, "model": {"name": "openai/whisper-small", "size_params": "244M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-small"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "zh"], "validated": true}
{"id": "whisper_var_008", "task_type": "speech_recognition", "task_description": "Whisper en ASR", "use_case": "Speech recognition - en", "dataset": {"name": "librispeech", "size": 10000, "format": "audio", "language": "en"}, "model": {"name": "openai/whisper-medium", "size_params": "769M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-medium"}, "training_config": {"learning_rate": 5e-06, "batch_size": 8, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "A100", "gpu_memory_gb": 40, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "en"], "validated": true}
{"id": "whisper_var_009", "task_type": "speech_recognition", "task_description": "Whisper hi ASR", "use_case": "Speech recognition - hi", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "hi"}, "model": {"name": "openai/whisper-tiny", "size_params": "39M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-tiny"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "hi"], "validated": true}
{"id": "whisper_var_010", "task_type": "speech_recognition", "task_description": "Whisper fr ASR", "use_case": "Speech recognition - fr", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "fr"}, "model": {"name": "openai/whisper-base", "size_params": "74M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-base"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "fr"], "validated": true}
{"id": "whisper_var_011", "task_type": "speech_recognition", "task_description": "Whisper de ASR", "use_case": "Speech recognition - de", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "de"}, "model": {"name": "openai/whisper-small", "size_params": "244M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-small"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "de"], "validated": true}
{"id": "whisper_var_012", "task_type": "speech_recognition", "task_description": "Whisper es ASR", "use_case": "Speech recognition - es", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "es"}, "model": {"name": "openai/whisper-medium", "size_params": "769M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-medium"}, "training_config": {"learning_rate": 5e-06, "batch_size": 8, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "A100", "gpu_memory_gb": 40, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "es"], "validated": true}
{"id": "whisper_var_013", "task_type": "speech_recognition", "task_description": "Whisper ko ASR", "use_case": "Speech recognition - ko", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "ko"}, "model": {"name": "openai/whisper-tiny", "size_params": "39M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-tiny"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "ko"], "validated": true}
{"id": "whisper_var_014", "task_type": "speech_recognition", "task_description": "Whisper zh ASR", "use_case": "Speech recognition - zh", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "zh"}, "model": {"name": "openai/whisper-base", "size_params": "74M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-base"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "zh"], "validated": true}
{"id": "whisper_var_015", "task_type": "speech_recognition", "task_description": "Whisper en ASR", "use_case": "Speech recognition - en", "dataset": {"name": "librispeech", "size": 10000, "format": "audio", "language": "en"}, "model": {"name": "openai/whisper-small", "size_params": "244M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-small"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "en"], "validated": true}
{"id": "whisper_var_016", "task_type": "speech_recognition", "task_description": "Whisper hi ASR", "use_case": "Speech recognition - hi", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "hi"}, "model": {"name": "openai/whisper-medium", "size_params": "769M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-medium"}, "training_config": {"learning_rate": 5e-06, "batch_size": 8, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "A100", "gpu_memory_gb": 40, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "hi"], "validated": true}
{"id": "whisper_var_017", "task_type": "speech_recognition", "task_description": "Whisper fr ASR", "use_case": "Speech recognition - fr", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "fr"}, "model": {"name": "openai/whisper-tiny", "size_params": "39M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-tiny"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "fr"], "validated": true}
{"id": "whisper_var_018", "task_type": "speech_recognition", "task_description": "Whisper de ASR", "use_case": "Speech recognition - de", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "de"}, "model": {"name": "openai/whisper-base", "size_params": "74M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-base"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "de"], "validated": true}
{"id": "whisper_var_019", "task_type": "speech_recognition", "task_description": "Whisper es ASR", "use_case": "Speech recognition - es", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "es"}, "model": {"name": "openai/whisper-small", "size_params": "244M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-small"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "es"], "validated": true}
{"id": "whisper_var_020", "task_type": "speech_recognition", "task_description": "Whisper ko ASR", "use_case": "Speech recognition - ko", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "ko"}, "model": {"name": "openai/whisper-medium", "size_params": "769M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-medium"}, "training_config": {"learning_rate": 5e-06, "batch_size": 8, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "A100", "gpu_memory_gb": 40, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "ko"], "validated": true}
{"id": "whisper_var_021", "task_type": "speech_recognition", "task_description": "Whisper zh ASR", "use_case": "Speech recognition - zh", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "zh"}, "model": {"name": "openai/whisper-tiny", "size_params": "39M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-tiny"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "zh"], "validated": true}
{"id": "whisper_var_022", "task_type": "speech_recognition", "task_description": "Whisper en ASR", "use_case": "Speech recognition - en", "dataset": {"name": "librispeech", "size": 10000, "format": "audio", "language": "en"}, "model": {"name": "openai/whisper-base", "size_params": "74M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-base"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "en"], "validated": true}
{"id": "whisper_var_023", "task_type": "speech_recognition", "task_description": "Whisper hi ASR", "use_case": "Speech recognition - hi", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "hi"}, "model": {"name": "openai/whisper-small", "size_params": "244M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-small"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "hi"], "validated": true}
{"id": "whisper_var_024", "task_type": "speech_recognition", "task_description": "Whisper fr ASR", "use_case": "Speech recognition - fr", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "fr"}, "model": {"name": "openai/whisper-medium", "size_params": "769M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-medium"}, "training_config": {"learning_rate": 5e-06, "batch_size": 8, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "A100", "gpu_memory_gb": 40, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "fr"], "validated": true}
{"id": "whisper_var_025", "task_type": "speech_recognition", "task_description": "Whisper de ASR", "use_case": "Speech recognition - de", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "de"}, "model": {"name": "openai/whisper-tiny", "size_params": "39M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-tiny"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "de"], "validated": true}
{"id": "whisper_var_026", "task_type": "speech_recognition", "task_description": "Whisper es ASR", "use_case": "Speech recognition - es", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "es"}, "model": {"name": "openai/whisper-base", "size_params": "74M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-base"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "es"], "validated": true}
{"id": "whisper_var_027", "task_type": "speech_recognition", "task_description": "Whisper ko ASR", "use_case": "Speech recognition - ko", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "ko"}, "model": {"name": "openai/whisper-small", "size_params": "244M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-small"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "ko"], "validated": true}
{"id": "whisper_var_028", "task_type": "speech_recognition", "task_description": "Whisper zh ASR", "use_case": "Speech recognition - zh", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "zh"}, "model": {"name": "openai/whisper-medium", "size_params": "769M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-medium"}, "training_config": {"learning_rate": 5e-06, "batch_size": 8, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "A100", "gpu_memory_gb": 40, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "zh"], "validated": true}
{"id": "whisper_var_029", "task_type": "speech_recognition", "task_description": "Whisper en ASR", "use_case": "Speech recognition - en", "dataset": {"name": "librispeech", "size": 10000, "format": "audio", "language": "en"}, "model": {"name": "openai/whisper-tiny", "size_params": "39M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-tiny"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "en"], "validated": true}
{"id": "whisper_var_030", "task_type": "speech_recognition", "task_description": "Whisper hi ASR", "use_case": "Speech recognition - hi", "dataset": {"name": "common_voice", "size": 10000, "format": "audio", "language": "hi"}, "model": {"name": "openai/whisper-base", "size_params": "74M", "architecture": "WhisperForConditionalGeneration", "hf_hub_id": "openai/whisper-base"}, "training_config": {"learning_rate": 1e-05, "batch_size": 16, "max_steps": 4000, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "whisper_variations", "tags": ["asr", "speech", "whisper", "hi"], "validated": true}
{"id": "vit_var_001", "task_type": "image_classification", "task_description": "Vision transformer on beans", "use_case": "Image classification - beans", "dataset": {"name": "beans", "size": 1034, "format": "image"}, "model": {"name": "google/vit-base-patch16-224", "size_params": "86M", "architecture": "ViTForImageClassification", "hf_hub_id": "google/vit-base-patch16-224"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 4, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "vision_variations", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vit_var_002", "task_type": "image_classification", "task_description": "Vision transformer on cifar10", "use_case": "Image classification - cifar10", "dataset": {"name": "cifar10", "size": 50000, "format": "image"}, "model": {"name": "google/vit-large-patch16-224", "size_params": "304M", "architecture": "ViTForImageClassification", "hf_hub_id": "google/vit-large-patch16-224"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 4, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "V100", "gpu_memory_gb": 32, "quantization": "none"}, "source": "vision_variations", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vit_var_003", "task_type": "image_classification", "task_description": "Vision transformer on cifar100", "use_case": "Image classification - cifar100", "dataset": {"name": "cifar100", "size": 50000, "format": "image"}, "model": {"name": "facebook/deit-small-patch16-224", "size_params": "86M", "architecture": "DeiTForImageClassification", "hf_hub_id": "facebook/deit-small-patch16-224"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 4, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "vision_variations", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vit_var_004", "task_type": "image_classification", "task_description": "Vision transformer on food101", "use_case": "Image classification - food101", "dataset": {"name": "food101", "size": 50000, "format": "image"}, "model": {"name": "facebook/deit-base-patch16-224", "size_params": "86M", "architecture": "DeiTForImageClassification", "hf_hub_id": "facebook/deit-base-patch16-224"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 4, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "vision_variations", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vit_var_005", "task_type": "image_classification", "task_description": "Vision transformer on beans", "use_case": "Image classification - beans", "dataset": {"name": "beans", "size": 1034, "format": "image"}, "model": {"name": "google/vit-base-patch16-224", "size_params": "86M", "architecture": "ViTForImageClassification", "hf_hub_id": "google/vit-base-patch16-224"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 4, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "vision_variations", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vit_var_006", "task_type": "image_classification", "task_description": "Vision transformer on cifar10", "use_case": "Image classification - cifar10", "dataset": {"name": "cifar10", "size": 50000, "format": "image"}, "model": {"name": "google/vit-large-patch16-224", "size_params": "304M", "architecture": "ViTForImageClassification", "hf_hub_id": "google/vit-large-patch16-224"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 4, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "V100", "gpu_memory_gb": 32, "quantization": "none"}, "source": "vision_variations", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vit_var_007", "task_type": "image_classification", "task_description": "Vision transformer on cifar100", "use_case": "Image classification - cifar100", "dataset": {"name": "cifar100", "size": 50000, "format": "image"}, "model": {"name": "facebook/deit-small-patch16-224", "size_params": "86M", "architecture": "DeiTForImageClassification", "hf_hub_id": "facebook/deit-small-patch16-224"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 4, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "vision_variations", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vit_var_008", "task_type": "image_classification", "task_description": "Vision transformer on food101", "use_case": "Image classification - food101", "dataset": {"name": "food101", "size": 50000, "format": "image"}, "model": {"name": "facebook/deit-base-patch16-224", "size_params": "86M", "architecture": "DeiTForImageClassification", "hf_hub_id": "facebook/deit-base-patch16-224"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 4, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "vision_variations", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vit_var_009", "task_type": "image_classification", "task_description": "Vision transformer on beans", "use_case": "Image classification - beans", "dataset": {"name": "beans", "size": 1034, "format": "image"}, "model": {"name": "google/vit-base-patch16-224", "size_params": "86M", "architecture": "ViTForImageClassification", "hf_hub_id": "google/vit-base-patch16-224"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 4, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "vision_variations", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vit_var_010", "task_type": "image_classification", "task_description": "Vision transformer on cifar10", "use_case": "Image classification - cifar10", "dataset": {"name": "cifar10", "size": 50000, "format": "image"}, "model": {"name": "google/vit-large-patch16-224", "size_params": "304M", "architecture": "ViTForImageClassification", "hf_hub_id": "google/vit-large-patch16-224"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 4, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "V100", "gpu_memory_gb": 32, "quantization": "none"}, "source": "vision_variations", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vit_var_011", "task_type": "image_classification", "task_description": "Vision transformer on cifar100", "use_case": "Image classification - cifar100", "dataset": {"name": "cifar100", "size": 50000, "format": "image"}, "model": {"name": "facebook/deit-small-patch16-224", "size_params": "86M", "architecture": "DeiTForImageClassification", "hf_hub_id": "facebook/deit-small-patch16-224"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 4, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "vision_variations", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vit_var_012", "task_type": "image_classification", "task_description": "Vision transformer on food101", "use_case": "Image classification - food101", "dataset": {"name": "food101", "size": 50000, "format": "image"}, "model": {"name": "facebook/deit-base-patch16-224", "size_params": "86M", "architecture": "DeiTForImageClassification", "hf_hub_id": "facebook/deit-base-patch16-224"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 4, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "vision_variations", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vit_var_013", "task_type": "image_classification", "task_description": "Vision transformer on beans", "use_case": "Image classification - beans", "dataset": {"name": "beans", "size": 1034, "format": "image"}, "model": {"name": "google/vit-base-patch16-224", "size_params": "86M", "architecture": "ViTForImageClassification", "hf_hub_id": "google/vit-base-patch16-224"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 4, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "vision_variations", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vit_var_014", "task_type": "image_classification", "task_description": "Vision transformer on cifar10", "use_case": "Image classification - cifar10", "dataset": {"name": "cifar10", "size": 50000, "format": "image"}, "model": {"name": "google/vit-large-patch16-224", "size_params": "304M", "architecture": "ViTForImageClassification", "hf_hub_id": "google/vit-large-patch16-224"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 4, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "V100", "gpu_memory_gb": 32, "quantization": "none"}, "source": "vision_variations", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vit_var_015", "task_type": "image_classification", "task_description": "Vision transformer on cifar100", "use_case": "Image classification - cifar100", "dataset": {"name": "cifar100", "size": 50000, "format": "image"}, "model": {"name": "facebook/deit-small-patch16-224", "size_params": "86M", "architecture": "DeiTForImageClassification", "hf_hub_id": "facebook/deit-small-patch16-224"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 4, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "vision_variations", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vit_var_016", "task_type": "image_classification", "task_description": "Vision transformer on food101", "use_case": "Image classification - food101", "dataset": {"name": "food101", "size": 50000, "format": "image"}, "model": {"name": "facebook/deit-base-patch16-224", "size_params": "86M", "architecture": "DeiTForImageClassification", "hf_hub_id": "facebook/deit-base-patch16-224"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 4, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "vision_variations", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vit_var_017", "task_type": "image_classification", "task_description": "Vision transformer on beans", "use_case": "Image classification - beans", "dataset": {"name": "beans", "size": 1034, "format": "image"}, "model": {"name": "google/vit-base-patch16-224", "size_params": "86M", "architecture": "ViTForImageClassification", "hf_hub_id": "google/vit-base-patch16-224"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 4, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "vision_variations", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vit_var_018", "task_type": "image_classification", "task_description": "Vision transformer on cifar10", "use_case": "Image classification - cifar10", "dataset": {"name": "cifar10", "size": 50000, "format": "image"}, "model": {"name": "google/vit-large-patch16-224", "size_params": "304M", "architecture": "ViTForImageClassification", "hf_hub_id": "google/vit-large-patch16-224"}, "training_config": {"learning_rate": 5e-05, "num_epochs": 4, "batch_size": 8, "warmup_steps": 500}, "hardware_config": {"target_gpu": "V100", "gpu_memory_gb": 32, "quantization": "none"}, "source": "vision_variations", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vit_var_019", "task_type": "image_classification", "task_description": "Vision transformer on cifar100", "use_case": "Image classification - cifar100", "dataset": {"name": "cifar100", "size": 50000, "format": "image"}, "model": {"name": "facebook/deit-small-patch16-224", "size_params": "86M", "architecture": "DeiTForImageClassification", "hf_hub_id": "facebook/deit-small-patch16-224"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 4, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "vision_variations", "tags": ["vision", "image_classification"], "validated": true}
{"id": "vit_var_020", "task_type": "image_classification", "task_description": "Vision transformer on food101", "use_case": "Image classification - food101", "dataset": {"name": "food101", "size": 50000, "format": "image"}, "model": {"name": "facebook/deit-base-patch16-224", "size_params": "86M", "architecture": "DeiTForImageClassification", "hf_hub_id": "facebook/deit-base-patch16-224"}, "training_config": {"learning_rate": 0.0002, "num_epochs": 4, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "vision_variations", "tags": ["vision", "image_classification"], "validated": true}
{"id": "modern_llm_001", "task_type": "chatbot", "task_description": "gemma-2b instruction tuning", "use_case": "Modern LLM chatbot", "dataset": {"name": "guanaco-llama2-1k", "size": 1000, "format": "hf_dataset"}, "model": {"name": "google/gemma-2b", "size_params": "2B", "architecture": "GemmaForCausalLM", "hf_hub_id": "google/gemma-2b"}, "adapter": "lora", "lora_config": {"r": 16, "lora_alpha": 32, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "modern_llms", "tags": ["chatbot", "modern_llm"], "validated": true}
{"id": "modern_llm_002", "task_type": "chatbot", "task_description": "gemma-7b instruction tuning", "use_case": "Modern LLM chatbot", "dataset": {"name": "alpaca-cleaned", "size": 15000, "format": "hf_dataset"}, "model": {"name": "google/gemma-7b", "size_params": "7B", "architecture": "GemmaForCausalLM", "hf_hub_id": "google/gemma-7b"}, "adapter": "qlora", "lora_config": {"r": 32, "lora_alpha": 64, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "modern_llms", "tags": ["chatbot", "modern_llm"], "validated": true}
{"id": "modern_llm_003", "task_type": "chatbot", "task_description": "Mistral-7B-v0.1 instruction tuning", "use_case": "Modern LLM chatbot", "dataset": {"name": "dolly-15k", "size": 15000, "format": "hf_dataset"}, "model": {"name": "mistralai/Mistral-7B-v0.1", "size_params": "7B", "architecture": "MistralForCausalLM", "hf_hub_id": "mistralai/Mistral-7B-v0.1"}, "adapter": "qlora", "lora_config": {"r": 64, "lora_alpha": 128, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "modern_llms", "tags": ["chatbot", "modern_llm"], "validated": true}
{"id": "modern_llm_004", "task_type": "chatbot", "task_description": "gemma-2b instruction tuning", "use_case": "Modern LLM chatbot", "dataset": {"name": "guanaco-llama2-1k", "size": 1000, "format": "hf_dataset"}, "model": {"name": "google/gemma-2b", "size_params": "2B", "architecture": "GemmaForCausalLM", "hf_hub_id": "google/gemma-2b"}, "adapter": "lora", "lora_config": {"r": 16, "lora_alpha": 32, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "modern_llms", "tags": ["chatbot", "modern_llm"], "validated": true}
{"id": "modern_llm_005", "task_type": "chatbot", "task_description": "gemma-7b instruction tuning", "use_case": "Modern LLM chatbot", "dataset": {"name": "alpaca-cleaned", "size": 15000, "format": "hf_dataset"}, "model": {"name": "google/gemma-7b", "size_params": "7B", "architecture": "GemmaForCausalLM", "hf_hub_id": "google/gemma-7b"}, "adapter": "qlora", "lora_config": {"r": 32, "lora_alpha": 64, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "modern_llms", "tags": ["chatbot", "modern_llm"], "validated": true}
{"id": "modern_llm_006", "task_type": "chatbot", "task_description": "Mistral-7B-v0.1 instruction tuning", "use_case": "Modern LLM chatbot", "dataset": {"name": "dolly-15k", "size": 15000, "format": "hf_dataset"}, "model": {"name": "mistralai/Mistral-7B-v0.1", "size_params": "7B", "architecture": "MistralForCausalLM", "hf_hub_id": "mistralai/Mistral-7B-v0.1"}, "adapter": "qlora", "lora_config": {"r": 64, "lora_alpha": 128, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "modern_llms", "tags": ["chatbot", "modern_llm"], "validated": true}
{"id": "modern_llm_007", "task_type": "chatbot", "task_description": "gemma-2b instruction tuning", "use_case": "Modern LLM chatbot", "dataset": {"name": "guanaco-llama2-1k", "size": 1000, "format": "hf_dataset"}, "model": {"name": "google/gemma-2b", "size_params": "2B", "architecture": "GemmaForCausalLM", "hf_hub_id": "google/gemma-2b"}, "adapter": "lora", "lora_config": {"r": 16, "lora_alpha": 32, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "modern_llms", "tags": ["chatbot", "modern_llm"], "validated": true}
{"id": "modern_llm_008", "task_type": "chatbot", "task_description": "gemma-7b instruction tuning", "use_case": "Modern LLM chatbot", "dataset": {"name": "alpaca-cleaned", "size": 15000, "format": "hf_dataset"}, "model": {"name": "google/gemma-7b", "size_params": "7B", "architecture": "GemmaForCausalLM", "hf_hub_id": "google/gemma-7b"}, "adapter": "qlora", "lora_config": {"r": 32, "lora_alpha": 64, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "modern_llms", "tags": ["chatbot", "modern_llm"], "validated": true}
{"id": "modern_llm_009", "task_type": "chatbot", "task_description": "Mistral-7B-v0.1 instruction tuning", "use_case": "Modern LLM chatbot", "dataset": {"name": "dolly-15k", "size": 15000, "format": "hf_dataset"}, "model": {"name": "mistralai/Mistral-7B-v0.1", "size_params": "7B", "architecture": "MistralForCausalLM", "hf_hub_id": "mistralai/Mistral-7B-v0.1"}, "adapter": "qlora", "lora_config": {"r": 64, "lora_alpha": 128, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "modern_llms", "tags": ["chatbot", "modern_llm"], "validated": true}
{"id": "modern_llm_010", "task_type": "chatbot", "task_description": "gemma-2b instruction tuning", "use_case": "Modern LLM chatbot", "dataset": {"name": "guanaco-llama2-1k", "size": 1000, "format": "hf_dataset"}, "model": {"name": "google/gemma-2b", "size_params": "2B", "architecture": "GemmaForCausalLM", "hf_hub_id": "google/gemma-2b"}, "adapter": "lora", "lora_config": {"r": 16, "lora_alpha": 32, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "modern_llms", "tags": ["chatbot", "modern_llm"], "validated": true}
{"id": "modern_llm_011", "task_type": "chatbot", "task_description": "gemma-7b instruction tuning", "use_case": "Modern LLM chatbot", "dataset": {"name": "alpaca-cleaned", "size": 15000, "format": "hf_dataset"}, "model": {"name": "google/gemma-7b", "size_params": "7B", "architecture": "GemmaForCausalLM", "hf_hub_id": "google/gemma-7b"}, "adapter": "qlora", "lora_config": {"r": 32, "lora_alpha": 64, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "modern_llms", "tags": ["chatbot", "modern_llm"], "validated": true}
{"id": "modern_llm_012", "task_type": "chatbot", "task_description": "Mistral-7B-v0.1 instruction tuning", "use_case": "Modern LLM chatbot", "dataset": {"name": "dolly-15k", "size": 15000, "format": "hf_dataset"}, "model": {"name": "mistralai/Mistral-7B-v0.1", "size_params": "7B", "architecture": "MistralForCausalLM", "hf_hub_id": "mistralai/Mistral-7B-v0.1"}, "adapter": "qlora", "lora_config": {"r": 64, "lora_alpha": 128, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "modern_llms", "tags": ["chatbot", "modern_llm"], "validated": true}
{"id": "modern_llm_013", "task_type": "chatbot", "task_description": "gemma-2b instruction tuning", "use_case": "Modern LLM chatbot", "dataset": {"name": "guanaco-llama2-1k", "size": 1000, "format": "hf_dataset"}, "model": {"name": "google/gemma-2b", "size_params": "2B", "architecture": "GemmaForCausalLM", "hf_hub_id": "google/gemma-2b"}, "adapter": "lora", "lora_config": {"r": 16, "lora_alpha": 32, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "modern_llms", "tags": ["chatbot", "modern_llm"], "validated": true}
{"id": "modern_llm_014", "task_type": "chatbot", "task_description": "gemma-7b instruction tuning", "use_case": "Modern LLM chatbot", "dataset": {"name": "alpaca-cleaned", "size": 15000, "format": "hf_dataset"}, "model": {"name": "google/gemma-7b", "size_params": "7B", "architecture": "GemmaForCausalLM", "hf_hub_id": "google/gemma-7b"}, "adapter": "qlora", "lora_config": {"r": 32, "lora_alpha": 64, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "modern_llms", "tags": ["chatbot", "modern_llm"], "validated": true}
{"id": "modern_llm_015", "task_type": "chatbot", "task_description": "Mistral-7B-v0.1 instruction tuning", "use_case": "Modern LLM chatbot", "dataset": {"name": "dolly-15k", "size": 15000, "format": "hf_dataset"}, "model": {"name": "mistralai/Mistral-7B-v0.1", "size_params": "7B", "architecture": "MistralForCausalLM", "hf_hub_id": "mistralai/Mistral-7B-v0.1"}, "adapter": "qlora", "lora_config": {"r": 64, "lora_alpha": 128, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "modern_llms", "tags": ["chatbot", "modern_llm"], "validated": true}
{"id": "modern_llm_016", "task_type": "chatbot", "task_description": "gemma-2b instruction tuning", "use_case": "Modern LLM chatbot", "dataset": {"name": "guanaco-llama2-1k", "size": 1000, "format": "hf_dataset"}, "model": {"name": "google/gemma-2b", "size_params": "2B", "architecture": "GemmaForCausalLM", "hf_hub_id": "google/gemma-2b"}, "adapter": "lora", "lora_config": {"r": 16, "lora_alpha": 32, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "modern_llms", "tags": ["chatbot", "modern_llm"], "validated": true}
{"id": "modern_llm_017", "task_type": "chatbot", "task_description": "gemma-7b instruction tuning", "use_case": "Modern LLM chatbot", "dataset": {"name": "alpaca-cleaned", "size": 15000, "format": "hf_dataset"}, "model": {"name": "google/gemma-7b", "size_params": "7B", "architecture": "GemmaForCausalLM", "hf_hub_id": "google/gemma-7b"}, "adapter": "qlora", "lora_config": {"r": 32, "lora_alpha": 64, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "modern_llms", "tags": ["chatbot", "modern_llm"], "validated": true}
{"id": "modern_llm_018", "task_type": "chatbot", "task_description": "Mistral-7B-v0.1 instruction tuning", "use_case": "Modern LLM chatbot", "dataset": {"name": "dolly-15k", "size": 15000, "format": "hf_dataset"}, "model": {"name": "mistralai/Mistral-7B-v0.1", "size_params": "7B", "architecture": "MistralForCausalLM", "hf_hub_id": "mistralai/Mistral-7B-v0.1"}, "adapter": "qlora", "lora_config": {"r": 64, "lora_alpha": 128, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "modern_llms", "tags": ["chatbot", "modern_llm"], "validated": true}
{"id": "modern_llm_019", "task_type": "chatbot", "task_description": "gemma-2b instruction tuning", "use_case": "Modern LLM chatbot", "dataset": {"name": "guanaco-llama2-1k", "size": 1000, "format": "hf_dataset"}, "model": {"name": "google/gemma-2b", "size_params": "2B", "architecture": "GemmaForCausalLM", "hf_hub_id": "google/gemma-2b"}, "adapter": "lora", "lora_config": {"r": 16, "lora_alpha": 32, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "modern_llms", "tags": ["chatbot", "modern_llm"], "validated": true}
{"id": "modern_llm_020", "task_type": "chatbot", "task_description": "gemma-7b instruction tuning", "use_case": "Modern LLM chatbot", "dataset": {"name": "alpaca-cleaned", "size": 15000, "format": "hf_dataset"}, "model": {"name": "google/gemma-7b", "size_params": "7B", "architecture": "GemmaForCausalLM", "hf_hub_id": "google/gemma-7b"}, "adapter": "qlora", "lora_config": {"r": 32, "lora_alpha": 64, "target_modules": ["q_proj", "v_proj"]}, "training_config": {"learning_rate": 0.0002, "num_epochs": 3, "batch_size": 4, "gradient_accumulation_steps": 4}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "nf4"}, "source": "modern_llms", "tags": ["chatbot", "modern_llm"], "validated": true}
{"id": "roberta_001", "task_type": "classification", "task_description": "RoBERTa on sst2", "use_case": "Text classification", "dataset": {"name": "sst2", "size": 10000, "format": "hf_dataset"}, "model": {"name": "roberta-base", "size_params": "125M", "architecture": "RobertaForSequenceClassification", "hf_hub_id": "roberta-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "roberta_baselines", "tags": ["classification", "roberta"], "validated": true}
{"id": "roberta_002", "task_type": "classification", "task_description": "RoBERTa on imdb", "use_case": "Text classification", "dataset": {"name": "imdb", "size": 10000, "format": "hf_dataset"}, "model": {"name": "roberta-base", "size_params": "125M", "architecture": "RobertaForSequenceClassification", "hf_hub_id": "roberta-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "roberta_baselines", "tags": ["classification", "roberta"], "validated": true}
{"id": "roberta_003", "task_type": "classification", "task_description": "RoBERTa on mnli", "use_case": "Text classification", "dataset": {"name": "mnli", "size": 10000, "format": "hf_dataset"}, "model": {"name": "roberta-base", "size_params": "125M", "architecture": "RobertaForSequenceClassification", "hf_hub_id": "roberta-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "roberta_baselines", "tags": ["classification", "roberta"], "validated": true}
{"id": "roberta_004", "task_type": "classification", "task_description": "RoBERTa on rte", "use_case": "Text classification", "dataset": {"name": "rte", "size": 10000, "format": "hf_dataset"}, "model": {"name": "roberta-base", "size_params": "125M", "architecture": "RobertaForSequenceClassification", "hf_hub_id": "roberta-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "roberta_baselines", "tags": ["classification", "roberta"], "validated": true}
{"id": "roberta_005", "task_type": "classification", "task_description": "RoBERTa on cola", "use_case": "Text classification", "dataset": {"name": "cola", "size": 10000, "format": "hf_dataset"}, "model": {"name": "roberta-base", "size_params": "125M", "architecture": "RobertaForSequenceClassification", "hf_hub_id": "roberta-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "roberta_baselines", "tags": ["classification", "roberta"], "validated": true}
{"id": "roberta_006", "task_type": "classification", "task_description": "RoBERTa on sst2", "use_case": "Text classification", "dataset": {"name": "sst2", "size": 10000, "format": "hf_dataset"}, "model": {"name": "roberta-base", "size_params": "125M", "architecture": "RobertaForSequenceClassification", "hf_hub_id": "roberta-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "roberta_baselines", "tags": ["classification", "roberta"], "validated": true}
{"id": "roberta_007", "task_type": "classification", "task_description": "RoBERTa on imdb", "use_case": "Text classification", "dataset": {"name": "imdb", "size": 10000, "format": "hf_dataset"}, "model": {"name": "roberta-base", "size_params": "125M", "architecture": "RobertaForSequenceClassification", "hf_hub_id": "roberta-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "roberta_baselines", "tags": ["classification", "roberta"], "validated": true}
{"id": "roberta_008", "task_type": "classification", "task_description": "RoBERTa on mnli", "use_case": "Text classification", "dataset": {"name": "mnli", "size": 10000, "format": "hf_dataset"}, "model": {"name": "roberta-base", "size_params": "125M", "architecture": "RobertaForSequenceClassification", "hf_hub_id": "roberta-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "roberta_baselines", "tags": ["classification", "roberta"], "validated": true}
{"id": "roberta_009", "task_type": "classification", "task_description": "RoBERTa on rte", "use_case": "Text classification", "dataset": {"name": "rte", "size": 10000, "format": "hf_dataset"}, "model": {"name": "roberta-base", "size_params": "125M", "architecture": "RobertaForSequenceClassification", "hf_hub_id": "roberta-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "roberta_baselines", "tags": ["classification", "roberta"], "validated": true}
{"id": "roberta_010", "task_type": "classification", "task_description": "RoBERTa on cola", "use_case": "Text classification", "dataset": {"name": "cola", "size": 10000, "format": "hf_dataset"}, "model": {"name": "roberta-base", "size_params": "125M", "architecture": "RobertaForSequenceClassification", "hf_hub_id": "roberta-base"}, "training_config": {"learning_rate": 2e-05, "num_epochs": 3, "batch_size": 16, "warmup_steps": 500}, "hardware_config": {"target_gpu": "T4", "gpu_memory_gb": 16, "quantization": "none"}, "source": "roberta_baselines", "tags": ["classification", "roberta"], "validated": true}
